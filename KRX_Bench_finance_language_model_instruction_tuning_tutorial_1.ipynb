{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWnZuU7PVtZF"
      },
      "source": [
        "# KRX-Bench ì–¸ì–´ ëª¨ë¸ Instruction Tuning íŠœí† ë¦¬ì–¼\n",
        "- Unslothì™€ ê¸ˆìœµ ë„ë©”ì¸ í•©ì„± ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” íŠœí† ë¦¬ì–¼ì…ë‹ˆë‹¤.\n",
        "- UnslothëŠ” ì ì€ ì»´í“¨íŒ… ìì›ìœ¼ë¡œë„ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¹ ë¥´ê²Œ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n",
        "\n",
        "## íŠœí† ë¦¬ì–¼ í™˜ê²½ ë° ì„¸ë¶€ì‚¬í•­\n",
        "- ëª¨ë¸: [Meta-Llama-3.1-8B](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B)\n",
        "- ë°ì´í„°ì…‹: [amphora/krx-sample-instructions](https://huggingface.co/datasets/amphora/krx-sample-instructions)\n",
        "- í•™ìŠµ íˆ´: [Unsloth](https://github.com/unslothai/unsloth)\n",
        "- í•™ìŠµ ë°©ë²• : Supervised Fine-tuning with QLoRA(4bit)\n",
        "- í•™ìŠµ ì»´í“¨íŒ… í™˜ê²½: Google Colab T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjizHH4vVtZG"
      },
      "source": [
        "## 1. Unsloth ì„¤ì¹˜ ë° í•™ìŠµ í™˜ê²½ êµ¬ì¶•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S4DqZvT6VtZG"
      },
      "outputs": [],
      "source": [
        "# # Unsloth ì„¤ì¹˜ ë° ìµœì‹  ë²„ì „ ì—…ê·¸ë ˆì´ë“œ\n",
        "# !pip install unsloth\n",
        "# !pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "# !pip install trl bitsandbytes triton xformers peft\n",
        "\n",
        "# # GPUê°€ softcappingì„ ì§€ì›í•˜ëŠ” ê²½ìš°, Flash Attention 2 ì„¤ì¹˜\n",
        "# import torch\n",
        "# if torch.cuda.get_device_capability()[0] >= 8:\n",
        "#     !pip install --no-deps packaging ninja einops \"flash-attn>=2.6.3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNfOabrCVtZH"
      },
      "source": [
        "## 2. ëª¨ë¸ ë° ë°ì´í„°ì…‹ ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sK96swGiVtZH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "==((====))==  Unsloth 2024.10.7: Fast Qwen2 patching. Transformers = 4.44.2.\n",
            "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.69 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.0+cu124. CUDA = 8.6. CUDA Toolkit = 12.4.\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
            "Please update transformers, TRL and unsloth via:\n",
            "`pip install --upgrade --no-cache-dir unsloth git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git`\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048\n",
        "dtype = None # Noneìœ¼ë¡œ ì§€ì •í•  ê²½ìš° í•´ë‹¹ ì»´í“¨íŒ… ìœ ë‹›ì— ì•Œë§ì€ dtypeìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤. Tesla T4ì™€ V100ì˜ ê²½ìš°ì—ëŠ” Float16, Ampere+ ì´ìƒì˜ ê²½ìš°ì—ëŠ” Bfloat16ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.\n",
        "load_in_4bit = True # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê¸° ìœ„í•´ì„œëŠ” 4bit ì–‘ìí™”ë¥¼ ì‚¬ìš©í•˜ì‹¤ ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
        "\n",
        "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„ ì–¸\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Qwen/Qwen2-7B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    token = \"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\", # gated modelì„ ì‚¬ìš©í•  ê²½ìš° í—ˆê¹…í˜ì´ìŠ¤ í† í°ì„ ì…ë ¥í•´ì£¼ì‹œê¸¸ ë°”ë¼ê² ìŠµë‹ˆë‹¤.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model\n",
            "model.embed_tokens\n",
            "model.layers\n",
            "model.layers.0\n",
            "model.layers.0.self_attn\n",
            "model.layers.0.self_attn.q_proj\n",
            "model.layers.0.self_attn.k_proj\n",
            "model.layers.0.self_attn.v_proj\n",
            "model.layers.0.self_attn.o_proj\n",
            "model.layers.0.self_attn.rotary_emb\n",
            "model.layers.0.mlp\n",
            "model.layers.0.mlp.gate_proj\n",
            "model.layers.0.mlp.up_proj\n",
            "model.layers.0.mlp.down_proj\n",
            "model.layers.0.mlp.act_fn\n",
            "model.layers.0.input_layernorm\n",
            "model.layers.0.post_attention_layernorm\n",
            "model.layers.1\n",
            "model.layers.1.self_attn\n",
            "model.layers.1.self_attn.q_proj\n",
            "model.layers.1.self_attn.k_proj\n",
            "model.layers.1.self_attn.v_proj\n",
            "model.layers.1.self_attn.o_proj\n",
            "model.layers.1.self_attn.rotary_emb\n",
            "model.layers.1.mlp\n",
            "model.layers.1.mlp.gate_proj\n",
            "model.layers.1.mlp.up_proj\n",
            "model.layers.1.mlp.down_proj\n",
            "model.layers.1.mlp.act_fn\n",
            "model.layers.1.input_layernorm\n",
            "model.layers.1.post_attention_layernorm\n",
            "model.layers.2\n",
            "model.layers.2.self_attn\n",
            "model.layers.2.self_attn.q_proj\n",
            "model.layers.2.self_attn.k_proj\n",
            "model.layers.2.self_attn.v_proj\n",
            "model.layers.2.self_attn.o_proj\n",
            "model.layers.2.self_attn.rotary_emb\n",
            "model.layers.2.mlp\n",
            "model.layers.2.mlp.gate_proj\n",
            "model.layers.2.mlp.up_proj\n",
            "model.layers.2.mlp.down_proj\n",
            "model.layers.2.mlp.act_fn\n",
            "model.layers.2.input_layernorm\n",
            "model.layers.2.post_attention_layernorm\n",
            "model.layers.3\n",
            "model.layers.3.self_attn\n",
            "model.layers.3.self_attn.q_proj\n",
            "model.layers.3.self_attn.k_proj\n",
            "model.layers.3.self_attn.v_proj\n",
            "model.layers.3.self_attn.o_proj\n",
            "model.layers.3.self_attn.rotary_emb\n",
            "model.layers.3.mlp\n",
            "model.layers.3.mlp.gate_proj\n",
            "model.layers.3.mlp.up_proj\n",
            "model.layers.3.mlp.down_proj\n",
            "model.layers.3.mlp.act_fn\n",
            "model.layers.3.input_layernorm\n",
            "model.layers.3.post_attention_layernorm\n",
            "model.layers.4\n",
            "model.layers.4.self_attn\n",
            "model.layers.4.self_attn.q_proj\n",
            "model.layers.4.self_attn.k_proj\n",
            "model.layers.4.self_attn.v_proj\n",
            "model.layers.4.self_attn.o_proj\n",
            "model.layers.4.self_attn.rotary_emb\n",
            "model.layers.4.mlp\n",
            "model.layers.4.mlp.gate_proj\n",
            "model.layers.4.mlp.up_proj\n",
            "model.layers.4.mlp.down_proj\n",
            "model.layers.4.mlp.act_fn\n",
            "model.layers.4.input_layernorm\n",
            "model.layers.4.post_attention_layernorm\n",
            "model.layers.5\n",
            "model.layers.5.self_attn\n",
            "model.layers.5.self_attn.q_proj\n",
            "model.layers.5.self_attn.k_proj\n",
            "model.layers.5.self_attn.v_proj\n",
            "model.layers.5.self_attn.o_proj\n",
            "model.layers.5.self_attn.rotary_emb\n",
            "model.layers.5.mlp\n",
            "model.layers.5.mlp.gate_proj\n",
            "model.layers.5.mlp.up_proj\n",
            "model.layers.5.mlp.down_proj\n",
            "model.layers.5.mlp.act_fn\n",
            "model.layers.5.input_layernorm\n",
            "model.layers.5.post_attention_layernorm\n",
            "model.layers.6\n",
            "model.layers.6.self_attn\n",
            "model.layers.6.self_attn.q_proj\n",
            "model.layers.6.self_attn.k_proj\n",
            "model.layers.6.self_attn.v_proj\n",
            "model.layers.6.self_attn.o_proj\n",
            "model.layers.6.self_attn.rotary_emb\n",
            "model.layers.6.mlp\n",
            "model.layers.6.mlp.gate_proj\n",
            "model.layers.6.mlp.up_proj\n",
            "model.layers.6.mlp.down_proj\n",
            "model.layers.6.mlp.act_fn\n",
            "model.layers.6.input_layernorm\n",
            "model.layers.6.post_attention_layernorm\n",
            "model.layers.7\n",
            "model.layers.7.self_attn\n",
            "model.layers.7.self_attn.q_proj\n",
            "model.layers.7.self_attn.k_proj\n",
            "model.layers.7.self_attn.v_proj\n",
            "model.layers.7.self_attn.o_proj\n",
            "model.layers.7.self_attn.rotary_emb\n",
            "model.layers.7.mlp\n",
            "model.layers.7.mlp.gate_proj\n",
            "model.layers.7.mlp.up_proj\n",
            "model.layers.7.mlp.down_proj\n",
            "model.layers.7.mlp.act_fn\n",
            "model.layers.7.input_layernorm\n",
            "model.layers.7.post_attention_layernorm\n",
            "model.layers.8\n",
            "model.layers.8.self_attn\n",
            "model.layers.8.self_attn.q_proj\n",
            "model.layers.8.self_attn.k_proj\n",
            "model.layers.8.self_attn.v_proj\n",
            "model.layers.8.self_attn.o_proj\n",
            "model.layers.8.self_attn.rotary_emb\n",
            "model.layers.8.mlp\n",
            "model.layers.8.mlp.gate_proj\n",
            "model.layers.8.mlp.up_proj\n",
            "model.layers.8.mlp.down_proj\n",
            "model.layers.8.mlp.act_fn\n",
            "model.layers.8.input_layernorm\n",
            "model.layers.8.post_attention_layernorm\n",
            "model.layers.9\n",
            "model.layers.9.self_attn\n",
            "model.layers.9.self_attn.q_proj\n",
            "model.layers.9.self_attn.k_proj\n",
            "model.layers.9.self_attn.v_proj\n",
            "model.layers.9.self_attn.o_proj\n",
            "model.layers.9.self_attn.rotary_emb\n",
            "model.layers.9.mlp\n",
            "model.layers.9.mlp.gate_proj\n",
            "model.layers.9.mlp.up_proj\n",
            "model.layers.9.mlp.down_proj\n",
            "model.layers.9.mlp.act_fn\n",
            "model.layers.9.input_layernorm\n",
            "model.layers.9.post_attention_layernorm\n",
            "model.layers.10\n",
            "model.layers.10.self_attn\n",
            "model.layers.10.self_attn.q_proj\n",
            "model.layers.10.self_attn.k_proj\n",
            "model.layers.10.self_attn.v_proj\n",
            "model.layers.10.self_attn.o_proj\n",
            "model.layers.10.self_attn.rotary_emb\n",
            "model.layers.10.mlp\n",
            "model.layers.10.mlp.gate_proj\n",
            "model.layers.10.mlp.up_proj\n",
            "model.layers.10.mlp.down_proj\n",
            "model.layers.10.mlp.act_fn\n",
            "model.layers.10.input_layernorm\n",
            "model.layers.10.post_attention_layernorm\n",
            "model.layers.11\n",
            "model.layers.11.self_attn\n",
            "model.layers.11.self_attn.q_proj\n",
            "model.layers.11.self_attn.k_proj\n",
            "model.layers.11.self_attn.v_proj\n",
            "model.layers.11.self_attn.o_proj\n",
            "model.layers.11.self_attn.rotary_emb\n",
            "model.layers.11.mlp\n",
            "model.layers.11.mlp.gate_proj\n",
            "model.layers.11.mlp.up_proj\n",
            "model.layers.11.mlp.down_proj\n",
            "model.layers.11.mlp.act_fn\n",
            "model.layers.11.input_layernorm\n",
            "model.layers.11.post_attention_layernorm\n",
            "model.layers.12\n",
            "model.layers.12.self_attn\n",
            "model.layers.12.self_attn.q_proj\n",
            "model.layers.12.self_attn.k_proj\n",
            "model.layers.12.self_attn.v_proj\n",
            "model.layers.12.self_attn.o_proj\n",
            "model.layers.12.self_attn.rotary_emb\n",
            "model.layers.12.mlp\n",
            "model.layers.12.mlp.gate_proj\n",
            "model.layers.12.mlp.up_proj\n",
            "model.layers.12.mlp.down_proj\n",
            "model.layers.12.mlp.act_fn\n",
            "model.layers.12.input_layernorm\n",
            "model.layers.12.post_attention_layernorm\n",
            "model.layers.13\n",
            "model.layers.13.self_attn\n",
            "model.layers.13.self_attn.q_proj\n",
            "model.layers.13.self_attn.k_proj\n",
            "model.layers.13.self_attn.v_proj\n",
            "model.layers.13.self_attn.o_proj\n",
            "model.layers.13.self_attn.rotary_emb\n",
            "model.layers.13.mlp\n",
            "model.layers.13.mlp.gate_proj\n",
            "model.layers.13.mlp.up_proj\n",
            "model.layers.13.mlp.down_proj\n",
            "model.layers.13.mlp.act_fn\n",
            "model.layers.13.input_layernorm\n",
            "model.layers.13.post_attention_layernorm\n",
            "model.layers.14\n",
            "model.layers.14.self_attn\n",
            "model.layers.14.self_attn.q_proj\n",
            "model.layers.14.self_attn.k_proj\n",
            "model.layers.14.self_attn.v_proj\n",
            "model.layers.14.self_attn.o_proj\n",
            "model.layers.14.self_attn.rotary_emb\n",
            "model.layers.14.mlp\n",
            "model.layers.14.mlp.gate_proj\n",
            "model.layers.14.mlp.up_proj\n",
            "model.layers.14.mlp.down_proj\n",
            "model.layers.14.mlp.act_fn\n",
            "model.layers.14.input_layernorm\n",
            "model.layers.14.post_attention_layernorm\n",
            "model.layers.15\n",
            "model.layers.15.self_attn\n",
            "model.layers.15.self_attn.q_proj\n",
            "model.layers.15.self_attn.k_proj\n",
            "model.layers.15.self_attn.v_proj\n",
            "model.layers.15.self_attn.o_proj\n",
            "model.layers.15.self_attn.rotary_emb\n",
            "model.layers.15.mlp\n",
            "model.layers.15.mlp.gate_proj\n",
            "model.layers.15.mlp.up_proj\n",
            "model.layers.15.mlp.down_proj\n",
            "model.layers.15.mlp.act_fn\n",
            "model.layers.15.input_layernorm\n",
            "model.layers.15.post_attention_layernorm\n",
            "model.layers.16\n",
            "model.layers.16.self_attn\n",
            "model.layers.16.self_attn.q_proj\n",
            "model.layers.16.self_attn.k_proj\n",
            "model.layers.16.self_attn.v_proj\n",
            "model.layers.16.self_attn.o_proj\n",
            "model.layers.16.self_attn.rotary_emb\n",
            "model.layers.16.mlp\n",
            "model.layers.16.mlp.gate_proj\n",
            "model.layers.16.mlp.up_proj\n",
            "model.layers.16.mlp.down_proj\n",
            "model.layers.16.mlp.act_fn\n",
            "model.layers.16.input_layernorm\n",
            "model.layers.16.post_attention_layernorm\n",
            "model.layers.17\n",
            "model.layers.17.self_attn\n",
            "model.layers.17.self_attn.q_proj\n",
            "model.layers.17.self_attn.k_proj\n",
            "model.layers.17.self_attn.v_proj\n",
            "model.layers.17.self_attn.o_proj\n",
            "model.layers.17.self_attn.rotary_emb\n",
            "model.layers.17.mlp\n",
            "model.layers.17.mlp.gate_proj\n",
            "model.layers.17.mlp.up_proj\n",
            "model.layers.17.mlp.down_proj\n",
            "model.layers.17.mlp.act_fn\n",
            "model.layers.17.input_layernorm\n",
            "model.layers.17.post_attention_layernorm\n",
            "model.layers.18\n",
            "model.layers.18.self_attn\n",
            "model.layers.18.self_attn.q_proj\n",
            "model.layers.18.self_attn.k_proj\n",
            "model.layers.18.self_attn.v_proj\n",
            "model.layers.18.self_attn.o_proj\n",
            "model.layers.18.self_attn.rotary_emb\n",
            "model.layers.18.mlp\n",
            "model.layers.18.mlp.gate_proj\n",
            "model.layers.18.mlp.up_proj\n",
            "model.layers.18.mlp.down_proj\n",
            "model.layers.18.mlp.act_fn\n",
            "model.layers.18.input_layernorm\n",
            "model.layers.18.post_attention_layernorm\n",
            "model.layers.19\n",
            "model.layers.19.self_attn\n",
            "model.layers.19.self_attn.q_proj\n",
            "model.layers.19.self_attn.k_proj\n",
            "model.layers.19.self_attn.v_proj\n",
            "model.layers.19.self_attn.o_proj\n",
            "model.layers.19.self_attn.rotary_emb\n",
            "model.layers.19.mlp\n",
            "model.layers.19.mlp.gate_proj\n",
            "model.layers.19.mlp.up_proj\n",
            "model.layers.19.mlp.down_proj\n",
            "model.layers.19.mlp.act_fn\n",
            "model.layers.19.input_layernorm\n",
            "model.layers.19.post_attention_layernorm\n",
            "model.layers.20\n",
            "model.layers.20.self_attn\n",
            "model.layers.20.self_attn.q_proj\n",
            "model.layers.20.self_attn.k_proj\n",
            "model.layers.20.self_attn.v_proj\n",
            "model.layers.20.self_attn.o_proj\n",
            "model.layers.20.self_attn.rotary_emb\n",
            "model.layers.20.mlp\n",
            "model.layers.20.mlp.gate_proj\n",
            "model.layers.20.mlp.up_proj\n",
            "model.layers.20.mlp.down_proj\n",
            "model.layers.20.mlp.act_fn\n",
            "model.layers.20.input_layernorm\n",
            "model.layers.20.post_attention_layernorm\n",
            "model.layers.21\n",
            "model.layers.21.self_attn\n",
            "model.layers.21.self_attn.q_proj\n",
            "model.layers.21.self_attn.k_proj\n",
            "model.layers.21.self_attn.v_proj\n",
            "model.layers.21.self_attn.o_proj\n",
            "model.layers.21.self_attn.rotary_emb\n",
            "model.layers.21.mlp\n",
            "model.layers.21.mlp.gate_proj\n",
            "model.layers.21.mlp.up_proj\n",
            "model.layers.21.mlp.down_proj\n",
            "model.layers.21.mlp.act_fn\n",
            "model.layers.21.input_layernorm\n",
            "model.layers.21.post_attention_layernorm\n",
            "model.layers.22\n",
            "model.layers.22.self_attn\n",
            "model.layers.22.self_attn.q_proj\n",
            "model.layers.22.self_attn.k_proj\n",
            "model.layers.22.self_attn.v_proj\n",
            "model.layers.22.self_attn.o_proj\n",
            "model.layers.22.self_attn.rotary_emb\n",
            "model.layers.22.mlp\n",
            "model.layers.22.mlp.gate_proj\n",
            "model.layers.22.mlp.up_proj\n",
            "model.layers.22.mlp.down_proj\n",
            "model.layers.22.mlp.act_fn\n",
            "model.layers.22.input_layernorm\n",
            "model.layers.22.post_attention_layernorm\n",
            "model.layers.23\n",
            "model.layers.23.self_attn\n",
            "model.layers.23.self_attn.q_proj\n",
            "model.layers.23.self_attn.k_proj\n",
            "model.layers.23.self_attn.v_proj\n",
            "model.layers.23.self_attn.o_proj\n",
            "model.layers.23.self_attn.rotary_emb\n",
            "model.layers.23.mlp\n",
            "model.layers.23.mlp.gate_proj\n",
            "model.layers.23.mlp.up_proj\n",
            "model.layers.23.mlp.down_proj\n",
            "model.layers.23.mlp.act_fn\n",
            "model.layers.23.input_layernorm\n",
            "model.layers.23.post_attention_layernorm\n",
            "model.layers.24\n",
            "model.layers.24.self_attn\n",
            "model.layers.24.self_attn.q_proj\n",
            "model.layers.24.self_attn.k_proj\n",
            "model.layers.24.self_attn.v_proj\n",
            "model.layers.24.self_attn.o_proj\n",
            "model.layers.24.self_attn.rotary_emb\n",
            "model.layers.24.mlp\n",
            "model.layers.24.mlp.gate_proj\n",
            "model.layers.24.mlp.up_proj\n",
            "model.layers.24.mlp.down_proj\n",
            "model.layers.24.mlp.act_fn\n",
            "model.layers.24.input_layernorm\n",
            "model.layers.24.post_attention_layernorm\n",
            "model.layers.25\n",
            "model.layers.25.self_attn\n",
            "model.layers.25.self_attn.q_proj\n",
            "model.layers.25.self_attn.k_proj\n",
            "model.layers.25.self_attn.v_proj\n",
            "model.layers.25.self_attn.o_proj\n",
            "model.layers.25.self_attn.rotary_emb\n",
            "model.layers.25.mlp\n",
            "model.layers.25.mlp.gate_proj\n",
            "model.layers.25.mlp.up_proj\n",
            "model.layers.25.mlp.down_proj\n",
            "model.layers.25.mlp.act_fn\n",
            "model.layers.25.input_layernorm\n",
            "model.layers.25.post_attention_layernorm\n",
            "model.layers.26\n",
            "model.layers.26.self_attn\n",
            "model.layers.26.self_attn.q_proj\n",
            "model.layers.26.self_attn.k_proj\n",
            "model.layers.26.self_attn.v_proj\n",
            "model.layers.26.self_attn.o_proj\n",
            "model.layers.26.self_attn.rotary_emb\n",
            "model.layers.26.mlp\n",
            "model.layers.26.mlp.gate_proj\n",
            "model.layers.26.mlp.up_proj\n",
            "model.layers.26.mlp.down_proj\n",
            "model.layers.26.mlp.act_fn\n",
            "model.layers.26.input_layernorm\n",
            "model.layers.26.post_attention_layernorm\n",
            "model.layers.27\n",
            "model.layers.27.self_attn\n",
            "model.layers.27.self_attn.q_proj\n",
            "model.layers.27.self_attn.k_proj\n",
            "model.layers.27.self_attn.v_proj\n",
            "model.layers.27.self_attn.o_proj\n",
            "model.layers.27.self_attn.rotary_emb\n",
            "model.layers.27.mlp\n",
            "model.layers.27.mlp.gate_proj\n",
            "model.layers.27.mlp.up_proj\n",
            "model.layers.27.mlp.down_proj\n",
            "model.layers.27.mlp.act_fn\n",
            "model.layers.27.input_layernorm\n",
            "model.layers.27.post_attention_layernorm\n",
            "model.norm\n",
            "lm_head\n"
          ]
        }
      ],
      "source": [
        "def print_submodules(model, prefix=''):\n",
        "    for name, submodule in model.named_children():\n",
        "        full_name = f\"{prefix}.{name}\" if prefix else name\n",
        "        print(full_name)\n",
        "        print_submodules(submodule, full_name)\n",
        "\n",
        "# Run the function\n",
        "print_submodules(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u2mlY9pMVtZH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Not an error, but Unsloth cannot patch MLP layers with our manual autograd engine since either LoRA adapters\n",
            "are not enabled or a bias term (like in Qwen) is used.\n",
            "Unsloth 2024.10.7 patched 28 layers with 0 QKV layers, 28 O layers and 0 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "# LoRA Adapter ì„ ì–¸\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 256, # 0ì„ ë„˜ëŠ” ìˆ«ìë¥¼ ì„ íƒí•˜ì„¸ìš”. 8, 16, 32, 64, 128ì´ ì¶”ì²œë©ë‹ˆë‹¤.\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], # target moduleë„ ì ì ˆí•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "    lora_alpha = 64,\n",
        "    lora_dropout = 0, # ì–´ë–¤ ê°’ì´ë“  ì‚¬ìš©ë  ìˆ˜ ìˆì§€ë§Œ, 0ìœ¼ë¡œ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "    bias = \"none\", # ì–´ë–¤ ê°’ì´ë“  ì‚¬ìš©ë  ìˆ˜ ìˆì§€ë§Œ, \"none\"ìœ¼ë¡œ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
        "    use_gradient_checkpointing = \"unsloth\", # ë§¤ìš° ê¸´ contextì— ëŒ€í•´ True ë˜ëŠ” \"unsloth\"ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.\n",
        "    random_state = 42,\n",
        "    use_rslora = True,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loDn97x9VtZH"
      },
      "source": [
        "## 3. ë°ì´í„°ì…‹ ì „ì²˜ë¦¬\n",
        "ë°ì´í„°ì…‹ì€ í•œêµ­ì–´ ê¸ˆìœµ í•©ì„± ë°ì´í„°ì…‹ì¸ `amphora/krx-sample-instruction`ë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , ë°ì´í„°ì…‹ í…œí”Œë¦¿ìœ¼ë¡œëŠ” Alpaca promptì—ì„œ inputì„ ì œê±°í•œ í˜•íƒœì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jEDXXvLTVtZH"
      },
      "outputs": [],
      "source": [
        "prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"prompt\"]\n",
        "    outputs = examples[\"response\"]\n",
        "    texts = []\n",
        "    for instruction, output in zip(instructions, outputs):\n",
        "        text = prompt_format.format(instruction, output) + EOS_TOKEN # ë§ˆì§€ë§‰ì— eos tokenì„ ì¶”ê°€í•´ì¤Œìœ¼ë¡œì¨ ëª¨ë¸ì´ ì¶œë ¥ì„ ëë§ˆì¹  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.\n",
        "        texts.append(text)\n",
        "    return { \"formatted_text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"amphora/krx-sample-instructions\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'prompt': 'ìŒì•…ì‚°ì—…ì˜ ë””ì§€í„¸í™”ê°€ ì§„í–‰ë¨ì— ë”°ë¼, ì „í†µì ì¸ ìŒë°˜ ì¤‘ì‹¬ì˜ ìˆ˜ìµ ëª¨ë¸ì—ì„œ ë””ì§€í„¸ ìŒì•… ì„œë¹„ìŠ¤ ì¤‘ì‹¬ìœ¼ë¡œ ë³€í™”í–ˆìŒì„ ì„¤ëª…í•˜ëŠ”ë°, ì´ëŸ¬í•œ ë³€í™”ê°€ ì´ë£¨ì–´ì§„ ì£¼ëœ ì›ì¸ì€ ë¬´ì—‡ì´ë©°, ì´ì— ë”°ë¼ ì—…ê³„ê°€ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ê³  ìˆëŠ”ì§€ êµ¬ì²´ì ì¸ ì˜ˆë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ì‹œì˜¤.',\n",
              " 'response': 'ìŒì•…ì‚°ì—…ì˜ ë””ì§€í„¸í™” ì£¼ëœ ì›ì¸ì€ ì¸í„°ë„·ê³¼ Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒ ì„œë¹„ìŠ¤ì˜ ë°œë‹¬ë¡œ ì¸í•´ ì†Œë¹„ìë“¤ì´ ìŒì•…ì„ ì ‘ê·¼í•˜ê³  ì†Œë¹„í•˜ëŠ” ë°©ì‹ì´ ë³€í™”í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë””ì§€í„¸ í”Œë«í¼ì˜ ë“±ì¥ìœ¼ë¡œ ìŒì› ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤(ì˜ˆ: ë©œë¡ , ìŠ¤í¬í‹°íŒŒì´ ë“±)ê°€ ë³´í¸í™”ë˜ë©´ì„œ, ì†Œë¹„ìë“¤ì€ ê³¼ê±°ì˜ ìŒë°˜ êµ¬ë§¤ ëŒ€ì‹  êµ¬ë… ê¸°ë°˜ì˜ ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ìŒì•…ì— ì‰½ê²Œ ì ‘ê·¼í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\\nì´ì— ë”°ë¼ ìŒì•…ì—…ê³„ëŠ” ë‹¤ì–‘í•œ ëŒ€ì‘ ì „ëµì„ ë§ˆë ¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì•„í‹°ìŠ¤íŠ¸ë“¤ì€ ìŒì› ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ìµì„ ìµœì í™”í•˜ê¸° ìœ„í•´ SNSì™€ ìœ íŠœë¸Œë¥¼ í™œìš©í•œ ë§ˆì¼€íŒ…ì„ ê°•í™”í•˜ê³  ìˆìœ¼ë©°, ë¼ì´ë¸Œ ê³µì—° ë° íŒ¬ë¯¸íŒ…ê³¼ ê°™ì€ ì˜¤í”„ë¼ì¸ ì´ë²¤íŠ¸ë¥¼ í™•ëŒ€í•˜ì—¬ ì¶”ê°€ ìˆ˜ìµì„ ì°½ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì¼ë¶€ ìŒì•… ë ˆì´ë¸”ì€ ì•„í‹°ìŠ¤íŠ¸ì™€ì˜ í˜‘ì—…ì„ í†µí•´ ë…ì  ì½˜í…ì¸ ë¥¼ ì œì‘í•˜ê³ , ë©”íƒ€ë²„ìŠ¤ì™€ ê°™ì€ ìƒˆë¡œìš´ í”Œë«í¼ì„ ì´ìš©í•´ ê°€ìƒ ê³µì—°ì„ ê°œìµœí•˜ëŠ” ë“±ì˜ í˜ì‹ ì ì¸ ì ‘ê·¼ë²•ì„ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.',\n",
              " '__index_level_0__': 0,\n",
              " 'formatted_text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nìŒì•…ì‚°ì—…ì˜ ë””ì§€í„¸í™”ê°€ ì§„í–‰ë¨ì— ë”°ë¼, ì „í†µì ì¸ ìŒë°˜ ì¤‘ì‹¬ì˜ ìˆ˜ìµ ëª¨ë¸ì—ì„œ ë””ì§€í„¸ ìŒì•… ì„œë¹„ìŠ¤ ì¤‘ì‹¬ìœ¼ë¡œ ë³€í™”í–ˆìŒì„ ì„¤ëª…í•˜ëŠ”ë°, ì´ëŸ¬í•œ ë³€í™”ê°€ ì´ë£¨ì–´ì§„ ì£¼ëœ ì›ì¸ì€ ë¬´ì—‡ì´ë©°, ì´ì— ë”°ë¼ ì—…ê³„ê°€ ì–´ë–»ê²Œ ëŒ€ì‘í•˜ê³  ìˆëŠ”ì§€ êµ¬ì²´ì ì¸ ì˜ˆë¥¼ ë“¤ì–´ ì„¤ëª…í•˜ì‹œì˜¤.\\n\\n### Response:\\nìŒì•…ì‚°ì—…ì˜ ë””ì§€í„¸í™” ì£¼ëœ ì›ì¸ì€ ì¸í„°ë„·ê³¼ Ğ¼Ğ¾Ğ±Ğ¸Ğ»ÑŒ ì„œë¹„ìŠ¤ì˜ ë°œë‹¬ë¡œ ì¸í•´ ì†Œë¹„ìë“¤ì´ ìŒì•…ì„ ì ‘ê·¼í•˜ê³  ì†Œë¹„í•˜ëŠ” ë°©ì‹ì´ ë³€í™”í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë””ì§€í„¸ í”Œë«í¼ì˜ ë“±ì¥ìœ¼ë¡œ ìŒì› ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤(ì˜ˆ: ë©œë¡ , ìŠ¤í¬í‹°íŒŒì´ ë“±)ê°€ ë³´í¸í™”ë˜ë©´ì„œ, ì†Œë¹„ìë“¤ì€ ê³¼ê±°ì˜ ìŒë°˜ êµ¬ë§¤ ëŒ€ì‹  êµ¬ë… ê¸°ë°˜ì˜ ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ìŒì•…ì— ì‰½ê²Œ ì ‘ê·¼í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\\n\\nì´ì— ë”°ë¼ ìŒì•…ì—…ê³„ëŠ” ë‹¤ì–‘í•œ ëŒ€ì‘ ì „ëµì„ ë§ˆë ¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì•„í‹°ìŠ¤íŠ¸ë“¤ì€ ìŒì› ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ìµì„ ìµœì í™”í•˜ê¸° ìœ„í•´ SNSì™€ ìœ íŠœë¸Œë¥¼ í™œìš©í•œ ë§ˆì¼€íŒ…ì„ ê°•í™”í•˜ê³  ìˆìœ¼ë©°, ë¼ì´ë¸Œ ê³µì—° ë° íŒ¬ë¯¸íŒ…ê³¼ ê°™ì€ ì˜¤í”„ë¼ì¸ ì´ë²¤íŠ¸ë¥¼ í™•ëŒ€í•˜ì—¬ ì¶”ê°€ ìˆ˜ìµì„ ì°½ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì¼ë¶€ ìŒì•… ë ˆì´ë¸”ì€ ì•„í‹°ìŠ¤íŠ¸ì™€ì˜ í˜‘ì—…ì„ í†µí•´ ë…ì  ì½˜í…ì¸ ë¥¼ ì œì‘í•˜ê³ , ë©”íƒ€ë²„ìŠ¤ì™€ ê°™ì€ ìƒˆë¡œìš´ í”Œë«í¼ì„ ì´ìš©í•´ ê°€ìƒ ê³µì—°ì„ ê°œìµœí•˜ëŠ” ë“±ì˜ í˜ì‹ ì ì¸ ì ‘ê·¼ë²•ì„ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤.<|im_end|>'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNT3z9nNVtZH"
      },
      "source": [
        "## 4. ëª¨ë¸ í•™ìŠµ\n",
        "\n",
        "full trainì„ ìœ„í•´ì„œëŠ” `num_train_epochs=1`ë¡œ ì„¤ì •í•˜ê³ , `max_steps`ë¥¼ ì„¤ì •í•˜ì§€ ì•Šìœ¼ë©´ ë©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n7K5p11fVtZH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"formatted_text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Trueë¡œ ì„¤ì •í•˜ë©´ ì§§ì€ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” ë” ë¹ ë¥¸ í•™ìŠµ ì†ë„ë¡œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
        "    args = TrainingArguments( # TrainingArgumentsëŠ” ìì‹ ì˜ í•™ìŠµ í™˜ê²½ê³¼ ê¸°í˜¸ì— ë”°ë¼ ì ì ˆí•˜ê²Œ ì„¤ì •í•˜ë©´ ë©ë‹ˆë‹¤.\n",
        "        per_device_train_batch_size = 8,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 1,\n",
        "        # max_steps = 60,\n",
        "        learning_rate = 1e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 10,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 42,\n",
        "        output_dir = \"./outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "97c2KpwfbNmP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 25,951 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 8 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 32 | Total steps = 811\n",
            " \"-____-\"     Number of trainable parameters = 161,480,704\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n",
            "`pip install --upgrade --no-cache-dir unsloth git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git`\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='85' max='811' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 85/811 25:25 < 3:42:23, 0.05 it/s, Epoch 0.10/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.241400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.110600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.090700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.033500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.044100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.070100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.015000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZl4bf7ZVtZI"
      },
      "source": [
        "## 5. ëª¨ë¸ ì¶”ë¡ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHa2tCFgVtZI"
      },
      "outputs": [],
      "source": [
        "FastLanguageModel.for_inference(model)\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    prompt_format.format(\n",
        "        \"ìˆ˜ìš”ì™€ ê³µê¸‰ì˜ ì›ë¦¬ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì¤˜.\", # instruction\n",
        "        \"\", # output ìƒì„±ì„ ìœ„í•´ ë¹ˆ ì¹¸ìœ¼ë¡œ ì„¤ì •\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ9S7MWeVtZI"
      },
      "source": [
        "## 6. ëª¨ë¸ ì €ì¥ ë° ì—…ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DsyXPKqVtZI"
      },
      "outputs": [],
      "source": [
        "# LoRA Adapter ì €ì¥\n",
        "model.save_pretrained(\"lora_model\")\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "\n",
        "# Merged model ì €ì¥ ë° ì—…ë¡œë“œ\n",
        "model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "model.push_to_hub_merged(\"KR-X-AI/krx-qwen2-7b-instruct-v0\", tokenizer, save_method = \"merged_16bit\", token = \"\") # ê°œì¸ huggingface tokenì„ ì‚¬ìš©í•˜ì—¬ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAJJR1YVLYdg"
      },
      "source": [
        "## ì°¸ê³ ìë£Œ\n",
        "\n",
        "- [Unsloth GitHub](https://github.com/unslothai/unsloth)\n",
        "- [Unsloth Docs](https://docs.unsloth.ai/)\n",
        "- [Unsloth Meta-Llama-3.1-8B Finetuning Tutorial](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing)\n",
        "- [Huggingface PEFT](https://github.com/huggingface/peft)\n",
        "- [Huggingface TRL](https://github.com/huggingface/trl)\n",
        "- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)\n",
        "- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)\n",
        "- [FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning](https://arxiv.org/abs/2307.08691)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ir",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
