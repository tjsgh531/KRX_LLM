{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "env_path = os.path.join(os.getcwd(), 'KRX_LLM', '.env')\n",
    "load_dotenv(env_path)\n",
    "\n",
    "hf_token = os.getenv(\"HF_TEAM_TOKEN\")\n",
    "print(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.10.7: Fast Qwen2 patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.691 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 8.6. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:57<00:00, 14.44s/it]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/it]\n",
      "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
      "Please update transformers, TRL and unsloth via:\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model_name = 'KR-X-AI/krx-qwen2-7b-instruct-v2'\n",
    "max_seq_length = 2048\n",
    "dtype = None \n",
    "load_in_4bit = True \n",
    "\n",
    "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„ ì–¸\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = hf_token, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.10.7 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # 0ì„ ë„˜ëŠ” ìˆ«ìë¥¼ ì„ íƒí•˜ì„¸ìš”. 8, 16, 32, 64, 128ì´ ì¶”ì²œë©ë‹ˆë‹¤.\n",
    "     target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",], # target moduleë„ ì ì ˆí•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.1, # ì–´ë–¤ ê°’ì´ë“  ì‚¬ìš©ë  ìˆ˜ ìˆì§€ë§Œ, 0ìœ¼ë¡œ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "    bias = \"none\",    # ì–´ë–¤ ê°’ì´ë“  ì‚¬ìš©ë  ìˆ˜ ìˆì§€ë§Œ, \"none\"ìœ¼ë¡œ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "    use_gradient_checkpointing = \"unsloth\", # ë§¤ìš° ê¸´ contextì— ëŒ€í•´ True ë˜ëŠ” \"unsloth\"ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.\n",
    "    random_state = 42,\n",
    "    use_rslora = False,\n",
    "    loftq_config={\"quantization\": \"4bit\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### ì§ˆë¬¸: íŒŒìƒìƒí’ˆ, ì•Œê³ ë¦¬ì¦˜ ê±°ë˜, ê³ ì£¼íŒŒ ê±°ë˜ëŠ” ê°ê° ê¸ˆìœµì‹œì¥ì— ë‹¤ì–‘í•œ ì˜í–¥...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### ì§ˆë¬¸: IMFì™€ ì„¸ê³„ì€í–‰ì´ ê²½ì œ ì•ˆì •ì„±ì— ê¸°ì—¬í•˜ëŠ” ë°©ì‹ì—ì„œ, ë‹¤ìŒ ì¤‘ ê°€ì¥ ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### ì§ˆë¬¸: AIê°€ ì‹ ìš© í‰ê°€ ë° ì‚¬ê¸° íƒì§€ì— ì–´ë–»ê²Œ í™œìš©ë˜ê³  ìˆëŠ”ì§€ë¥¼ ë…¼ì˜í•  ë•Œ...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### ì§ˆë¬¸: AIê°€ ìì‚° ê´€ë¦¬ì—ì„œ ìƒì„±í•˜ëŠ” ê°€ì¹˜ë¥¼ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë„ì „ ê³¼...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### ì§ˆë¬¸: AI ê¸°ë°˜ ê¸ˆìœµ ì„œë¹„ìŠ¤ì—ì„œ ê³ ê° ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì—¬ëŸ¬ ì ‘ê·¼ ë°©...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer\n",
       "0  ### ì§ˆë¬¸: íŒŒìƒìƒí’ˆ, ì•Œê³ ë¦¬ì¦˜ ê±°ë˜, ê³ ì£¼íŒŒ ê±°ë˜ëŠ” ê°ê° ê¸ˆìœµì‹œì¥ì— ë‹¤ì–‘í•œ ì˜í–¥...      C\n",
       "1  ### ì§ˆë¬¸: IMFì™€ ì„¸ê³„ì€í–‰ì´ ê²½ì œ ì•ˆì •ì„±ì— ê¸°ì—¬í•˜ëŠ” ë°©ì‹ì—ì„œ, ë‹¤ìŒ ì¤‘ ê°€ì¥ ...      A\n",
       "2  ### ì§ˆë¬¸: AIê°€ ì‹ ìš© í‰ê°€ ë° ì‚¬ê¸° íƒì§€ì— ì–´ë–»ê²Œ í™œìš©ë˜ê³  ìˆëŠ”ì§€ë¥¼ ë…¼ì˜í•  ë•Œ...      E\n",
       "3  ### ì§ˆë¬¸: AIê°€ ìì‚° ê´€ë¦¬ì—ì„œ ìƒì„±í•˜ëŠ” ê°€ì¹˜ë¥¼ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë„ì „ ê³¼...      A\n",
       "4  ### ì§ˆë¬¸: AI ê¸°ë°˜ ê¸ˆìœµ ì„œë¹„ìŠ¤ì—ì„œ ê³ ê° ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì—¬ëŸ¬ ì ‘ê·¼ ë°©...      D"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset \n",
    "\n",
    "df = pd.read_csv('/root/KRX_LLM/data/fixed_sample_questions.csv')\n",
    "dataset = Dataset.from_pandas(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 999/999 [00:00<00:00, 61761.86 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': '### ì§ˆë¬¸: íŒŒìƒìƒí’ˆ, ì•Œê³ ë¦¬ì¦˜ ê±°ë˜, ê³ ì£¼íŒŒ ê±°ë˜ëŠ” ê°ê° ê¸ˆìœµì‹œì¥ì— ë‹¤ì–‘í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì†Œë“¤ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¤‘ ì´ë“¤ì´ ì‹œì¥ì˜ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ì‹ìœ¼ë¡œ ì˜³ì§€ ì•Šì€ ê²ƒì„ ê³ ë¥´ì‹œì˜¤.\\n### ì„ íƒì§€:\\nA. íŒŒìƒìƒí’ˆì€ ê°€ê²© ë³€ë™ìœ¼ë¡œë¶€í„° ìœ„í—˜ì„ ê´€ë¦¬í•˜ì—¬ ì‹œì¥ ì•ˆì •ì„±ì„ ë•ëŠ”ë‹¤.\\nB. ì•Œê³ ë¦¬ì¦˜ ê±°ë˜ëŠ” ìë™í™” ê³¼ì •ì„ í†µí•´ ê±°ë˜ ì†ë„ë¥¼ ë†’ì´ê³  ê°ì •ì  ê²°ì •ì„ ì¤„ì¸ë‹¤.\\nC. ê³ ì£¼íŒŒ ê±°ë˜ëŠ” ë‹¨ê¸° ê±°ë˜ë¥¼ í†µí•´ ì‹œì¥ ê°€ê²©ì´ ì‚¬ì‹¤ìƒì˜ ê°€ì¹˜ì™€ ë©€ì–´ì§€ê²Œ ë§Œë“ ë‹¤.\\nD. ì•Œê³ ë¦¬ì¦˜ ê±°ë˜ëŠ” ìœ ë™ì„±ì„ ë†’ì´ê³  ê°€ê²© ë°œê²¬ ê³¼ì •ì„ ê°œì„ í•œë‹¤.\\nE. íŒŒìƒìƒí’ˆì€ ì „ë°˜ì ìœ¼ë¡œ ì‹œì¥ì— ê°€ê²© ì•ˆì •ì„ ìœ ë°œí•˜ëŠ” ìš”ì†Œë¡œ ì‘ìš©í•œë‹¤.',\n",
       " 'answer': 'C',\n",
       " 'formatted_text': \"You're given a problem and options. You should read the given problem and options and solve them.\\n\\n### ì§ˆë¬¸: íŒŒìƒìƒí’ˆ, ì•Œê³ ë¦¬ì¦˜ ê±°ë˜, ê³ ì£¼íŒŒ ê±°ë˜ëŠ” ê°ê° ê¸ˆìœµì‹œì¥ì— ë‹¤ì–‘í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì†Œë“¤ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¤‘ ì´ë“¤ì´ ì‹œì¥ì˜ íš¨ìœ¨ì„±ì„ í–¥ìƒì‹œí‚¤ëŠ” ë°©ì‹ìœ¼ë¡œ ì˜³ì§€ ì•Šì€ ê²ƒì„ ê³ ë¥´ì‹œì˜¤.\\n### ì„ íƒì§€:\\nA. íŒŒìƒìƒí’ˆì€ ê°€ê²© ë³€ë™ìœ¼ë¡œë¶€í„° ìœ„í—˜ì„ ê´€ë¦¬í•˜ì—¬ ì‹œì¥ ì•ˆì •ì„±ì„ ë•ëŠ”ë‹¤.\\nB. ì•Œê³ ë¦¬ì¦˜ ê±°ë˜ëŠ” ìë™í™” ê³¼ì •ì„ í†µí•´ ê±°ë˜ ì†ë„ë¥¼ ë†’ì´ê³  ê°ì •ì  ê²°ì •ì„ ì¤„ì¸ë‹¤.\\nC. ê³ ì£¼íŒŒ ê±°ë˜ëŠ” ë‹¨ê¸° ê±°ë˜ë¥¼ í†µí•´ ì‹œì¥ ê°€ê²©ì´ ì‚¬ì‹¤ìƒì˜ ê°€ì¹˜ì™€ ë©€ì–´ì§€ê²Œ ë§Œë“ ë‹¤.\\nD. ì•Œê³ ë¦¬ì¦˜ ê±°ë˜ëŠ” ìœ ë™ì„±ì„ ë†’ì´ê³  ê°€ê²© ë°œê²¬ ê³¼ì •ì„ ê°œì„ í•œë‹¤.\\nE. íŒŒìƒìƒí’ˆì€ ì „ë°˜ì ìœ¼ë¡œ ì‹œì¥ì— ê°€ê²© ì•ˆì •ì„ ìœ ë°œí•˜ëŠ” ìš”ì†Œë¡œ ì‘ìš©í•œë‹¤.\\n\\n### ì •ë‹µ:\\nì´ ë¬¸ì œì˜ ì •ë‹µì€ Cì…ë‹ˆë‹¤.\\n<|im_end|>\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"You're given a problem and options. You should read the given problem and options and solve them.\n",
    "\n",
    "{}\n",
    "\n",
    "### ì •ë‹µ:\n",
    "ì´ ë¬¸ì œì˜ ì •ë‹µì€ {}ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompts_func(examples):\n",
    "    questions = examples['question']\n",
    "    answers = examples['answer']\n",
    "\n",
    "    texts = []\n",
    "    for q, a in zip(questions, answers):\n",
    "        text = prompt.format(q, a) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"formatted_text\": texts}\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 999/999 [00:00<00:00, 1716.01 examples/s]\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"formatted_text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Trueë¡œ ì„¤ì •í•˜ë©´ ì§§ì€ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ì„œëŠ” ë” ë¹ ë¥¸ í•™ìŠµ ì†ë„ë¡œë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "    args = TrainingArguments( # TrainingArgumentsëŠ” ìì‹ ì˜ í•™ìŠµ í™˜ê²½ê³¼ ê¸°í˜¸ì— ë”°ë¼ ì ì ˆí•˜ê²Œ ì„¤ì •í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_ratio = 0.03,\n",
    "        num_train_epochs = 3,\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 42,\n",
    "        output_dir = \"/krx/outputs\",\n",
    "        save_steps=100,  # ë§¤ 100 ìŠ¤í…ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥\n",
    "        save_total_limit=1,  # ìµœì‹  1ê°œì˜ ì²´í¬í¬ì¸íŠ¸ë§Œ ë³´ê´€\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
