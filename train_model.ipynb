{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "env_path = os.path.join(os.getcwd(), 'KRX_LLM', '.env')\n",
    "load_dotenv(env_path)\n",
    "\n",
    "hf_token = os.getenv(\"HF_TEAM_TOKEN\")\n",
    "print(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.10.7: Fast Qwen2 patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.691 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 8.6. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [00:57<00:00, 14.44s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]\n",
      "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
      "Please update transformers, TRL and unsloth via:\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model_name = 'KR-X-AI/krx-qwen2-7b-instruct-v2'\n",
    "max_seq_length = 2048\n",
    "dtype = None \n",
    "load_in_4bit = True \n",
    "\n",
    "# 모델 및 토크나이저 선언\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = hf_token, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.10.7 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # 0을 넘는 숫자를 선택하세요. 8, 16, 32, 64, 128이 추천됩니다.\n",
    "     target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",], # target module도 적절하게 조정할 수 있습니다.\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.1, # 어떤 값이든 사용될 수 있지만, 0으로 최적화되어 있습니다.\n",
    "    bias = \"none\",    # 어떤 값이든 사용될 수 있지만, \"none\"으로 최적화되어 있습니다.\n",
    "    use_gradient_checkpointing = \"unsloth\", # 매우 긴 context에 대해 True 또는 \"unsloth\"를 사용하십시오.\n",
    "    random_state = 42,\n",
    "    use_rslora = False,\n",
    "    loftq_config={\"quantization\": \"4bit\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### 질문: 파생상품, 알고리즘 거래, 고주파 거래는 각각 금융시장에 다양한 영향...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### 질문: IMF와 세계은행이 경제 안정성에 기여하는 방식에서, 다음 중 가장 ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### 질문: AI가 신용 평가 및 사기 탐지에 어떻게 활용되고 있는지를 논의할 때...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### 질문: AI가 자산 관리에서 생성하는 가치를 극대화하기 위해 필요한 도전 과...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### 질문: AI 기반 금융 서비스에서 고객 경험을 향상시키기 위한 여러 접근 방...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer\n",
       "0  ### 질문: 파생상품, 알고리즘 거래, 고주파 거래는 각각 금융시장에 다양한 영향...      C\n",
       "1  ### 질문: IMF와 세계은행이 경제 안정성에 기여하는 방식에서, 다음 중 가장 ...      A\n",
       "2  ### 질문: AI가 신용 평가 및 사기 탐지에 어떻게 활용되고 있는지를 논의할 때...      E\n",
       "3  ### 질문: AI가 자산 관리에서 생성하는 가치를 극대화하기 위해 필요한 도전 과...      A\n",
       "4  ### 질문: AI 기반 금융 서비스에서 고객 경험을 향상시키기 위한 여러 접근 방...      D"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset \n",
    "\n",
    "df = pd.read_csv('/root/KRX_LLM/data/fixed_sample_questions.csv')\n",
    "dataset = Dataset.from_pandas(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 999/999 [00:00<00:00, 61761.86 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': '### 질문: 파생상품, 알고리즘 거래, 고주파 거래는 각각 금융시장에 다양한 영향을 미치는 요소들입니다. 다음 중 이들이 시장의 효율성을 향상시키는 방식으로 옳지 않은 것을 고르시오.\\n### 선택지:\\nA. 파생상품은 가격 변동으로부터 위험을 관리하여 시장 안정성을 돕는다.\\nB. 알고리즘 거래는 자동화 과정을 통해 거래 속도를 높이고 감정적 결정을 줄인다.\\nC. 고주파 거래는 단기 거래를 통해 시장 가격이 사실상의 가치와 멀어지게 만든다.\\nD. 알고리즘 거래는 유동성을 높이고 가격 발견 과정을 개선한다.\\nE. 파생상품은 전반적으로 시장에 가격 안정을 유발하는 요소로 작용한다.',\n",
       " 'answer': 'C',\n",
       " 'formatted_text': \"You're given a problem and options. You should read the given problem and options and solve them.\\n\\n### 질문: 파생상품, 알고리즘 거래, 고주파 거래는 각각 금융시장에 다양한 영향을 미치는 요소들입니다. 다음 중 이들이 시장의 효율성을 향상시키는 방식으로 옳지 않은 것을 고르시오.\\n### 선택지:\\nA. 파생상품은 가격 변동으로부터 위험을 관리하여 시장 안정성을 돕는다.\\nB. 알고리즘 거래는 자동화 과정을 통해 거래 속도를 높이고 감정적 결정을 줄인다.\\nC. 고주파 거래는 단기 거래를 통해 시장 가격이 사실상의 가치와 멀어지게 만든다.\\nD. 알고리즘 거래는 유동성을 높이고 가격 발견 과정을 개선한다.\\nE. 파생상품은 전반적으로 시장에 가격 안정을 유발하는 요소로 작용한다.\\n\\n### 정답:\\n이 문제의 정답은 C입니다.\\n<|im_end|>\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"You're given a problem and options. You should read the given problem and options and solve them.\n",
    "\n",
    "{}\n",
    "\n",
    "### 정답:\n",
    "이 문제의 정답은 {}입니다.\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompts_func(examples):\n",
    "    questions = examples['question']\n",
    "    answers = examples['answer']\n",
    "\n",
    "    texts = []\n",
    "    for q, a in zip(questions, answers):\n",
    "        text = prompt.format(q, a) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"formatted_text\": texts}\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|██████████| 999/999 [00:00<00:00, 1716.01 examples/s]\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"formatted_text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # True로 설정하면 짧은 텍스트 데이터에 대해서는 더 빠른 학습 속도로를 보여줍니다.\n",
    "    args = TrainingArguments( # TrainingArguments는 자신의 학습 환경과 기호에 따라 적절하게 설정하면 됩니다.\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_ratio = 0.03,\n",
    "        num_train_epochs = 3,\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 42,\n",
    "        output_dir = \"/krx/outputs\",\n",
    "        save_steps=100,  # 매 100 스텝마다 체크포인트 저장\n",
    "        save_total_limit=1,  # 최신 1개의 체크포인트만 보관\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 999 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 2\n",
      "\\        /    Total batch size = 8 | Total steps = 375\n",
      " \"-____-\"     Number of trainable parameters = 40,370,176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/375 03:35 < 06:11, 0.63 it/s, Epoch 1.10/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.810500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.209400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.110100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.058300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.047200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.947400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "[\n",
    "    \"\"\"\n",
    "    다음 중 화폐의 시간가치에 관한 설명으로 옳지 않은 것은 무엇인가?\n",
    "\n",
    "A. 월 복리의 경우, 매월 적용되는 이자율은 연간 명목 이자율을 1/12로 나누어 산출한다.\n",
    "B. 투자 원금 및 기타 조건이 동일할 경우, 단리 방식보다 복리 방식에서 발생하는 이자가 더 크다.\n",
    "C. 일시불로 지급될 금액의 현재 가치는 미래 가치를 일정 기간 동안 할인율을 적용해 산출할 수 있다.\n",
    "D. 1,000,000원을 연 5% 복리로 2년 동안 예치했을 경우, 만기에 받을 세전 이자는 100,000원이다.\n",
    "    \"\"\"\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    \"\"\"\n",
    "다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
    "### 질문: 다음 중 우리나라 주식시장 매매 제도에 대한 기술로 맞는 것은?\n",
    "### 선택지: \n",
    "A. 개장 시간은 오전 10시다.\n",
    "B. 유가증권시장의 가격 제한폭은 전일 종가 대비 상하 15%이다.\n",
    "C. 코스닥시장에는 가격 제한폭이 없다.\n",
    "D. 점심시간(12~1시)에는 휴장한다.\n",
    "E. 동시호가는 폐장 시간에만 적용한다.\n",
    "F. K-OTC시장의 가격 제한폭은 전일 종가 대비 상하 30%이다.\n",
    "G. K-OTC시장의 운영시간은 09:00부터 16:00까지이다.\n",
    "    \"\"\"\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"krx-qwen2-7b-instruct-v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA Adapter 저장\n",
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")\n",
    "\n",
    "# Merged model 저장 및 업로드\n",
    "model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "model.push_to_hub_merged(model_name, tokenizer, save_method = \"merged_16bit\", token = hf_token) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
