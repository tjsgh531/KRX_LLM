{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "env_path = os.path.join(os.getcwd(), 'KRX_LLM', '.env')\n",
    "load_dotenv(env_path)\n",
    "\n",
    "hf_token = os.getenv(\"HF_TEAM_TOKEN\")\n",
    "print(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.10.7: Fast Qwen2 patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.691 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu124. CUDA = 8.6. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [00:57<00:00, 14.44s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]\n",
      "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
      "Please update transformers, TRL and unsloth via:\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model_name = 'KR-X-AI/krx-qwen2-7b-instruct-v2'\n",
    "max_seq_length = 2048\n",
    "dtype = None \n",
    "load_in_4bit = True \n",
    "\n",
    "# 모델 및 토크나이저 선언\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    token = hf_token, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.10.7 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # 0을 넘는 숫자를 선택하세요. 8, 16, 32, 64, 128이 추천됩니다.\n",
    "     target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",], # target module도 적절하게 조정할 수 있습니다.\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.1, # 어떤 값이든 사용될 수 있지만, 0으로 최적화되어 있습니다.\n",
    "    bias = \"none\",    # 어떤 값이든 사용될 수 있지만, \"none\"으로 최적화되어 있습니다.\n",
    "    use_gradient_checkpointing = \"unsloth\", # 매우 긴 context에 대해 True 또는 \"unsloth\"를 사용하십시오.\n",
    "    random_state = 42,\n",
    "    use_rslora = False,\n",
    "    loftq_config={\"quantization\": \"4bit\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### 질문: 파생상품, 알고리즘 거래, 고주파 거래는 각각 금융시장에 다양한 영향...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### 질문: IMF와 세계은행이 경제 안정성에 기여하는 방식에서, 다음 중 가장 ...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### 질문: AI가 신용 평가 및 사기 탐지에 어떻게 활용되고 있는지를 논의할 때...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### 질문: AI가 자산 관리에서 생성하는 가치를 극대화하기 위해 필요한 도전 과...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### 질문: AI 기반 금융 서비스에서 고객 경험을 향상시키기 위한 여러 접근 방...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question answer\n",
       "0  ### 질문: 파생상품, 알고리즘 거래, 고주파 거래는 각각 금융시장에 다양한 영향...      C\n",
       "1  ### 질문: IMF와 세계은행이 경제 안정성에 기여하는 방식에서, 다음 중 가장 ...      A\n",
       "2  ### 질문: AI가 신용 평가 및 사기 탐지에 어떻게 활용되고 있는지를 논의할 때...      E\n",
       "3  ### 질문: AI가 자산 관리에서 생성하는 가치를 극대화하기 위해 필요한 도전 과...      A\n",
       "4  ### 질문: AI 기반 금융 서비스에서 고객 경험을 향상시키기 위한 여러 접근 방...      D"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset \n",
    "\n",
    "df = pd.read_csv('/root/KRX_LLM/data/fixed_sample_questions.csv')\n",
    "dataset = Dataset.from_pandas(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 999/999 [00:00<00:00, 61761.86 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': '### 질문: 파생상품, 알고리즘 거래, 고주파 거래는 각각 금융시장에 다양한 영향을 미치는 요소들입니다. 다음 중 이들이 시장의 효율성을 향상시키는 방식으로 옳지 않은 것을 고르시오.\\n### 선택지:\\nA. 파생상품은 가격 변동으로부터 위험을 관리하여 시장 안정성을 돕는다.\\nB. 알고리즘 거래는 자동화 과정을 통해 거래 속도를 높이고 감정적 결정을 줄인다.\\nC. 고주파 거래는 단기 거래를 통해 시장 가격이 사실상의 가치와 멀어지게 만든다.\\nD. 알고리즘 거래는 유동성을 높이고 가격 발견 과정을 개선한다.\\nE. 파생상품은 전반적으로 시장에 가격 안정을 유발하는 요소로 작용한다.',\n",
       " 'answer': 'C',\n",
       " 'formatted_text': \"You're given a problem and options. You should read the given problem and options and solve them.\\n\\n### 질문: 파생상품, 알고리즘 거래, 고주파 거래는 각각 금융시장에 다양한 영향을 미치는 요소들입니다. 다음 중 이들이 시장의 효율성을 향상시키는 방식으로 옳지 않은 것을 고르시오.\\n### 선택지:\\nA. 파생상품은 가격 변동으로부터 위험을 관리하여 시장 안정성을 돕는다.\\nB. 알고리즘 거래는 자동화 과정을 통해 거래 속도를 높이고 감정적 결정을 줄인다.\\nC. 고주파 거래는 단기 거래를 통해 시장 가격이 사실상의 가치와 멀어지게 만든다.\\nD. 알고리즘 거래는 유동성을 높이고 가격 발견 과정을 개선한다.\\nE. 파생상품은 전반적으로 시장에 가격 안정을 유발하는 요소로 작용한다.\\n\\n### 정답:\\n이 문제의 정답은 C입니다.\\n<|im_end|>\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"You're given a problem and options. You should read the given problem and options and solve them.\n",
    "\n",
    "{}\n",
    "\n",
    "### 정답:\n",
    "이 문제의 정답은 {}입니다.\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "def formatting_prompts_func(examples):\n",
    "    questions = examples['question']\n",
    "    answers = examples['answer']\n",
    "\n",
    "    texts = []\n",
    "    for q, a in zip(questions, answers):\n",
    "        text = prompt.format(q, a) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"formatted_text\": texts}\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|██████████| 999/999 [00:00<00:00, 1716.01 examples/s]\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"formatted_text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # True로 설정하면 짧은 텍스트 데이터에 대해서는 더 빠른 학습 속도로를 보여줍니다.\n",
    "    args = TrainingArguments( # TrainingArguments는 자신의 학습 환경과 기호에 따라 적절하게 설정하면 됩니다.\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_ratio = 0.03,\n",
    "        num_train_epochs = 3,\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 42,\n",
    "        output_dir = \"/krx/outputs\",\n",
    "        save_steps=100,  # 매 100 스텝마다 체크포인트 저장\n",
    "        save_total_limit=1,  # 최신 1개의 체크포인트만 보관\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
