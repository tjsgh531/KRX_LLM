{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjizHH4vVtZG"
   },
   "source": [
    "## 1. Unsloth 설치 및 학습 환경 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "S4DqZvT6VtZG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in /opt/conda/envs/ir/lib/python3.10/site-packages (2024.10.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: unsloth 2024.10.7\n",
      "Uninstalling unsloth-2024.10.7:\n",
      "  Successfully uninstalled unsloth-2024.10.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-6vm91c7t/unsloth_c364f6fd461b463ca423beb3014d3a1c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-6vm91c7t/unsloth_c364f6fd461b463ca423beb3014d3a1c\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 9ca13b836f647e67d6e9ca8bb712403ffaadd607\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: unsloth-zoo in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.10.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2)\n",
      "Requirement already satisfied: tyro in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.11)\n",
      "Requirement already satisfied: transformers>=4.44.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.44.2)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.5)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.25.1)\n",
      "Requirement already satisfied: hf-transfer in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/ir/lib/python3.10/site-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/ir/lib/python3.10/site-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/envs/ir/lib/python3.10/site-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/envs/ir/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/envs/ir/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n",
      "Requirement already satisfied: triton in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.0.1)\n",
      "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1,>=0.7.9 in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.6)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.10.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/ir/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/ir/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from sympy==1.13.1->torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/ir/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/ir/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from jinja2->torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.1.5)\n",
      "Building wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unsloth: filename=unsloth-2024.10.7-py3-none-any.whl size=163864 sha256=584de67ebba61cd003d2cd71bfba9869ba1ba0d77a4a90ac77775c4f87a2c0f3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-spnj21xm/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
      "Successfully built unsloth\n",
      "Installing collected packages: unsloth\n",
      "Successfully installed unsloth-2024.10.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: trl in /opt/conda/envs/ir/lib/python3.10/site-packages (0.8.6)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/envs/ir/lib/python3.10/site-packages (0.43.1)\n",
      "Requirement already satisfied: triton in /opt/conda/envs/ir/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: xformers in /opt/conda/envs/ir/lib/python3.10/site-packages (0.0.28.post2)\n",
      "Requirement already satisfied: peft in /opt/conda/envs/ir/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from trl) (2.5.0)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from trl) (4.44.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from trl) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /opt/conda/envs/ir/lib/python3.10/site-packages (from trl) (1.0.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/envs/ir/lib/python3.10/site-packages (from trl) (3.0.1)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/envs/ir/lib/python3.10/site-packages (from trl) (0.8.11)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/ir/lib/python3.10/site-packages (from triton) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/ir/lib/python3.10/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/ir/lib/python3.10/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/ir/lib/python3.10/site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: safetensors in /opt/conda/envs/ir/lib/python3.10/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from peft) (0.25.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/ir/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/ir/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/envs/ir/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/envs/ir/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.9.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/envs/ir/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets->trl) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets->trl) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/ir/lib/python3.10/site-packages (from datasets->trl) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets->trl) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/ir/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/ir/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/ir/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/envs/ir/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/ir/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/ir/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/ir/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: packaging in /opt/conda/envs/ir/lib/python3.10/site-packages (23.2)\n",
      "Collecting ninja\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting einops\n",
      "  Using cached einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flash-attn>=2.6.3\n",
      "  Using cached flash_attn-2.6.3.tar.gz (2.6 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[20 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m error: pathspec 'csrc/cutlass' did not match any file(s) known to git\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m torch.__version__  = 2.5.0+cu124\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m /tmp/pip-install-9zm9v6jp/flash-attn_834d780b2e774e078d5ab8dae58b8a41/setup.py:95: UserWarning: flash_attn was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-9zm9v6jp/flash-attn_834d780b2e774e078d5ab8dae58b8a41/setup.py\", line 179, in <module>\n",
      "  \u001b[31m   \u001b[0m     CUDAExtension(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/ir/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1078, in CUDAExtension\n",
      "  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/ir/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1209, in library_paths\n",
      "  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/envs/ir/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2416, in _join_cuda_home\n",
      "  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n",
      "  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "# # Unsloth 설치 및 최신 버전 업그레이드\n",
    "# !pip install unsloth\n",
    "# !pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "# !pip install trl bitsandbytes triton xformers peft\n",
    "\n",
    "# # GPU가 softcapping을 지원하는 경우, Flash Attention 2 설치\n",
    "# import torch\n",
    "# if torch.cuda.get_device_capability()[0] >= 8:\n",
    "#     !pip install --no-deps packaging ninja einops \"flash-attn>=2.6.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNfOabrCVtZH"
   },
   "source": [
    "## 2. 모델 및 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sK96swGiVtZH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.10.7: Fast Qwen2 patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.691 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.0+cu124. CUDA = 8.6. CUDA Toolkit = 12.4.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
      "Please update transformers, TRL and unsloth via:\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048\n",
    "dtype = None # None으로 지정할 경우 해당 컴퓨팅 유닛에 알맞은 dtype으로 저장됩니다. Tesla T4와 V100의 경우에는 Float16, Ampere+ 이상의 경우에는 Bfloat16으로 설정됩니다.\n",
    "load_in_4bit = True # 메모리 사용량을 줄이기 위해서는 4bit 양자화를 사용하실 것을 권장합니다.\n",
    "\n",
    "# 모델 및 토크나이저 선언\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Qwen/Qwen2-7B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # gated model을 사용할 경우 허깅페이스 토큰을 입력해주시길 바라겠습니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "model.embed_tokens\n",
      "model.layers\n",
      "model.layers.0\n",
      "model.layers.0.self_attn\n",
      "model.layers.0.self_attn.q_proj\n",
      "model.layers.0.self_attn.k_proj\n",
      "model.layers.0.self_attn.v_proj\n",
      "model.layers.0.self_attn.o_proj\n",
      "model.layers.0.self_attn.rotary_emb\n",
      "model.layers.0.mlp\n",
      "model.layers.0.mlp.gate_proj\n",
      "model.layers.0.mlp.up_proj\n",
      "model.layers.0.mlp.down_proj\n",
      "model.layers.0.mlp.act_fn\n",
      "model.layers.0.input_layernorm\n",
      "model.layers.0.post_attention_layernorm\n",
      "model.layers.1\n",
      "model.layers.1.self_attn\n",
      "model.layers.1.self_attn.q_proj\n",
      "model.layers.1.self_attn.k_proj\n",
      "model.layers.1.self_attn.v_proj\n",
      "model.layers.1.self_attn.o_proj\n",
      "model.layers.1.self_attn.rotary_emb\n",
      "model.layers.1.mlp\n",
      "model.layers.1.mlp.gate_proj\n",
      "model.layers.1.mlp.up_proj\n",
      "model.layers.1.mlp.down_proj\n",
      "model.layers.1.mlp.act_fn\n",
      "model.layers.1.input_layernorm\n",
      "model.layers.1.post_attention_layernorm\n",
      "model.layers.2\n",
      "model.layers.2.self_attn\n",
      "model.layers.2.self_attn.q_proj\n",
      "model.layers.2.self_attn.k_proj\n",
      "model.layers.2.self_attn.v_proj\n",
      "model.layers.2.self_attn.o_proj\n",
      "model.layers.2.self_attn.rotary_emb\n",
      "model.layers.2.mlp\n",
      "model.layers.2.mlp.gate_proj\n",
      "model.layers.2.mlp.up_proj\n",
      "model.layers.2.mlp.down_proj\n",
      "model.layers.2.mlp.act_fn\n",
      "model.layers.2.input_layernorm\n",
      "model.layers.2.post_attention_layernorm\n",
      "model.layers.3\n",
      "model.layers.3.self_attn\n",
      "model.layers.3.self_attn.q_proj\n",
      "model.layers.3.self_attn.k_proj\n",
      "model.layers.3.self_attn.v_proj\n",
      "model.layers.3.self_attn.o_proj\n",
      "model.layers.3.self_attn.rotary_emb\n",
      "model.layers.3.mlp\n",
      "model.layers.3.mlp.gate_proj\n",
      "model.layers.3.mlp.up_proj\n",
      "model.layers.3.mlp.down_proj\n",
      "model.layers.3.mlp.act_fn\n",
      "model.layers.3.input_layernorm\n",
      "model.layers.3.post_attention_layernorm\n",
      "model.layers.4\n",
      "model.layers.4.self_attn\n",
      "model.layers.4.self_attn.q_proj\n",
      "model.layers.4.self_attn.k_proj\n",
      "model.layers.4.self_attn.v_proj\n",
      "model.layers.4.self_attn.o_proj\n",
      "model.layers.4.self_attn.rotary_emb\n",
      "model.layers.4.mlp\n",
      "model.layers.4.mlp.gate_proj\n",
      "model.layers.4.mlp.up_proj\n",
      "model.layers.4.mlp.down_proj\n",
      "model.layers.4.mlp.act_fn\n",
      "model.layers.4.input_layernorm\n",
      "model.layers.4.post_attention_layernorm\n",
      "model.layers.5\n",
      "model.layers.5.self_attn\n",
      "model.layers.5.self_attn.q_proj\n",
      "model.layers.5.self_attn.k_proj\n",
      "model.layers.5.self_attn.v_proj\n",
      "model.layers.5.self_attn.o_proj\n",
      "model.layers.5.self_attn.rotary_emb\n",
      "model.layers.5.mlp\n",
      "model.layers.5.mlp.gate_proj\n",
      "model.layers.5.mlp.up_proj\n",
      "model.layers.5.mlp.down_proj\n",
      "model.layers.5.mlp.act_fn\n",
      "model.layers.5.input_layernorm\n",
      "model.layers.5.post_attention_layernorm\n",
      "model.layers.6\n",
      "model.layers.6.self_attn\n",
      "model.layers.6.self_attn.q_proj\n",
      "model.layers.6.self_attn.k_proj\n",
      "model.layers.6.self_attn.v_proj\n",
      "model.layers.6.self_attn.o_proj\n",
      "model.layers.6.self_attn.rotary_emb\n",
      "model.layers.6.mlp\n",
      "model.layers.6.mlp.gate_proj\n",
      "model.layers.6.mlp.up_proj\n",
      "model.layers.6.mlp.down_proj\n",
      "model.layers.6.mlp.act_fn\n",
      "model.layers.6.input_layernorm\n",
      "model.layers.6.post_attention_layernorm\n",
      "model.layers.7\n",
      "model.layers.7.self_attn\n",
      "model.layers.7.self_attn.q_proj\n",
      "model.layers.7.self_attn.k_proj\n",
      "model.layers.7.self_attn.v_proj\n",
      "model.layers.7.self_attn.o_proj\n",
      "model.layers.7.self_attn.rotary_emb\n",
      "model.layers.7.mlp\n",
      "model.layers.7.mlp.gate_proj\n",
      "model.layers.7.mlp.up_proj\n",
      "model.layers.7.mlp.down_proj\n",
      "model.layers.7.mlp.act_fn\n",
      "model.layers.7.input_layernorm\n",
      "model.layers.7.post_attention_layernorm\n",
      "model.layers.8\n",
      "model.layers.8.self_attn\n",
      "model.layers.8.self_attn.q_proj\n",
      "model.layers.8.self_attn.k_proj\n",
      "model.layers.8.self_attn.v_proj\n",
      "model.layers.8.self_attn.o_proj\n",
      "model.layers.8.self_attn.rotary_emb\n",
      "model.layers.8.mlp\n",
      "model.layers.8.mlp.gate_proj\n",
      "model.layers.8.mlp.up_proj\n",
      "model.layers.8.mlp.down_proj\n",
      "model.layers.8.mlp.act_fn\n",
      "model.layers.8.input_layernorm\n",
      "model.layers.8.post_attention_layernorm\n",
      "model.layers.9\n",
      "model.layers.9.self_attn\n",
      "model.layers.9.self_attn.q_proj\n",
      "model.layers.9.self_attn.k_proj\n",
      "model.layers.9.self_attn.v_proj\n",
      "model.layers.9.self_attn.o_proj\n",
      "model.layers.9.self_attn.rotary_emb\n",
      "model.layers.9.mlp\n",
      "model.layers.9.mlp.gate_proj\n",
      "model.layers.9.mlp.up_proj\n",
      "model.layers.9.mlp.down_proj\n",
      "model.layers.9.mlp.act_fn\n",
      "model.layers.9.input_layernorm\n",
      "model.layers.9.post_attention_layernorm\n",
      "model.layers.10\n",
      "model.layers.10.self_attn\n",
      "model.layers.10.self_attn.q_proj\n",
      "model.layers.10.self_attn.k_proj\n",
      "model.layers.10.self_attn.v_proj\n",
      "model.layers.10.self_attn.o_proj\n",
      "model.layers.10.self_attn.rotary_emb\n",
      "model.layers.10.mlp\n",
      "model.layers.10.mlp.gate_proj\n",
      "model.layers.10.mlp.up_proj\n",
      "model.layers.10.mlp.down_proj\n",
      "model.layers.10.mlp.act_fn\n",
      "model.layers.10.input_layernorm\n",
      "model.layers.10.post_attention_layernorm\n",
      "model.layers.11\n",
      "model.layers.11.self_attn\n",
      "model.layers.11.self_attn.q_proj\n",
      "model.layers.11.self_attn.k_proj\n",
      "model.layers.11.self_attn.v_proj\n",
      "model.layers.11.self_attn.o_proj\n",
      "model.layers.11.self_attn.rotary_emb\n",
      "model.layers.11.mlp\n",
      "model.layers.11.mlp.gate_proj\n",
      "model.layers.11.mlp.up_proj\n",
      "model.layers.11.mlp.down_proj\n",
      "model.layers.11.mlp.act_fn\n",
      "model.layers.11.input_layernorm\n",
      "model.layers.11.post_attention_layernorm\n",
      "model.layers.12\n",
      "model.layers.12.self_attn\n",
      "model.layers.12.self_attn.q_proj\n",
      "model.layers.12.self_attn.k_proj\n",
      "model.layers.12.self_attn.v_proj\n",
      "model.layers.12.self_attn.o_proj\n",
      "model.layers.12.self_attn.rotary_emb\n",
      "model.layers.12.mlp\n",
      "model.layers.12.mlp.gate_proj\n",
      "model.layers.12.mlp.up_proj\n",
      "model.layers.12.mlp.down_proj\n",
      "model.layers.12.mlp.act_fn\n",
      "model.layers.12.input_layernorm\n",
      "model.layers.12.post_attention_layernorm\n",
      "model.layers.13\n",
      "model.layers.13.self_attn\n",
      "model.layers.13.self_attn.q_proj\n",
      "model.layers.13.self_attn.k_proj\n",
      "model.layers.13.self_attn.v_proj\n",
      "model.layers.13.self_attn.o_proj\n",
      "model.layers.13.self_attn.rotary_emb\n",
      "model.layers.13.mlp\n",
      "model.layers.13.mlp.gate_proj\n",
      "model.layers.13.mlp.up_proj\n",
      "model.layers.13.mlp.down_proj\n",
      "model.layers.13.mlp.act_fn\n",
      "model.layers.13.input_layernorm\n",
      "model.layers.13.post_attention_layernorm\n",
      "model.layers.14\n",
      "model.layers.14.self_attn\n",
      "model.layers.14.self_attn.q_proj\n",
      "model.layers.14.self_attn.k_proj\n",
      "model.layers.14.self_attn.v_proj\n",
      "model.layers.14.self_attn.o_proj\n",
      "model.layers.14.self_attn.rotary_emb\n",
      "model.layers.14.mlp\n",
      "model.layers.14.mlp.gate_proj\n",
      "model.layers.14.mlp.up_proj\n",
      "model.layers.14.mlp.down_proj\n",
      "model.layers.14.mlp.act_fn\n",
      "model.layers.14.input_layernorm\n",
      "model.layers.14.post_attention_layernorm\n",
      "model.layers.15\n",
      "model.layers.15.self_attn\n",
      "model.layers.15.self_attn.q_proj\n",
      "model.layers.15.self_attn.k_proj\n",
      "model.layers.15.self_attn.v_proj\n",
      "model.layers.15.self_attn.o_proj\n",
      "model.layers.15.self_attn.rotary_emb\n",
      "model.layers.15.mlp\n",
      "model.layers.15.mlp.gate_proj\n",
      "model.layers.15.mlp.up_proj\n",
      "model.layers.15.mlp.down_proj\n",
      "model.layers.15.mlp.act_fn\n",
      "model.layers.15.input_layernorm\n",
      "model.layers.15.post_attention_layernorm\n",
      "model.layers.16\n",
      "model.layers.16.self_attn\n",
      "model.layers.16.self_attn.q_proj\n",
      "model.layers.16.self_attn.k_proj\n",
      "model.layers.16.self_attn.v_proj\n",
      "model.layers.16.self_attn.o_proj\n",
      "model.layers.16.self_attn.rotary_emb\n",
      "model.layers.16.mlp\n",
      "model.layers.16.mlp.gate_proj\n",
      "model.layers.16.mlp.up_proj\n",
      "model.layers.16.mlp.down_proj\n",
      "model.layers.16.mlp.act_fn\n",
      "model.layers.16.input_layernorm\n",
      "model.layers.16.post_attention_layernorm\n",
      "model.layers.17\n",
      "model.layers.17.self_attn\n",
      "model.layers.17.self_attn.q_proj\n",
      "model.layers.17.self_attn.k_proj\n",
      "model.layers.17.self_attn.v_proj\n",
      "model.layers.17.self_attn.o_proj\n",
      "model.layers.17.self_attn.rotary_emb\n",
      "model.layers.17.mlp\n",
      "model.layers.17.mlp.gate_proj\n",
      "model.layers.17.mlp.up_proj\n",
      "model.layers.17.mlp.down_proj\n",
      "model.layers.17.mlp.act_fn\n",
      "model.layers.17.input_layernorm\n",
      "model.layers.17.post_attention_layernorm\n",
      "model.layers.18\n",
      "model.layers.18.self_attn\n",
      "model.layers.18.self_attn.q_proj\n",
      "model.layers.18.self_attn.k_proj\n",
      "model.layers.18.self_attn.v_proj\n",
      "model.layers.18.self_attn.o_proj\n",
      "model.layers.18.self_attn.rotary_emb\n",
      "model.layers.18.mlp\n",
      "model.layers.18.mlp.gate_proj\n",
      "model.layers.18.mlp.up_proj\n",
      "model.layers.18.mlp.down_proj\n",
      "model.layers.18.mlp.act_fn\n",
      "model.layers.18.input_layernorm\n",
      "model.layers.18.post_attention_layernorm\n",
      "model.layers.19\n",
      "model.layers.19.self_attn\n",
      "model.layers.19.self_attn.q_proj\n",
      "model.layers.19.self_attn.k_proj\n",
      "model.layers.19.self_attn.v_proj\n",
      "model.layers.19.self_attn.o_proj\n",
      "model.layers.19.self_attn.rotary_emb\n",
      "model.layers.19.mlp\n",
      "model.layers.19.mlp.gate_proj\n",
      "model.layers.19.mlp.up_proj\n",
      "model.layers.19.mlp.down_proj\n",
      "model.layers.19.mlp.act_fn\n",
      "model.layers.19.input_layernorm\n",
      "model.layers.19.post_attention_layernorm\n",
      "model.layers.20\n",
      "model.layers.20.self_attn\n",
      "model.layers.20.self_attn.q_proj\n",
      "model.layers.20.self_attn.k_proj\n",
      "model.layers.20.self_attn.v_proj\n",
      "model.layers.20.self_attn.o_proj\n",
      "model.layers.20.self_attn.rotary_emb\n",
      "model.layers.20.mlp\n",
      "model.layers.20.mlp.gate_proj\n",
      "model.layers.20.mlp.up_proj\n",
      "model.layers.20.mlp.down_proj\n",
      "model.layers.20.mlp.act_fn\n",
      "model.layers.20.input_layernorm\n",
      "model.layers.20.post_attention_layernorm\n",
      "model.layers.21\n",
      "model.layers.21.self_attn\n",
      "model.layers.21.self_attn.q_proj\n",
      "model.layers.21.self_attn.k_proj\n",
      "model.layers.21.self_attn.v_proj\n",
      "model.layers.21.self_attn.o_proj\n",
      "model.layers.21.self_attn.rotary_emb\n",
      "model.layers.21.mlp\n",
      "model.layers.21.mlp.gate_proj\n",
      "model.layers.21.mlp.up_proj\n",
      "model.layers.21.mlp.down_proj\n",
      "model.layers.21.mlp.act_fn\n",
      "model.layers.21.input_layernorm\n",
      "model.layers.21.post_attention_layernorm\n",
      "model.layers.22\n",
      "model.layers.22.self_attn\n",
      "model.layers.22.self_attn.q_proj\n",
      "model.layers.22.self_attn.k_proj\n",
      "model.layers.22.self_attn.v_proj\n",
      "model.layers.22.self_attn.o_proj\n",
      "model.layers.22.self_attn.rotary_emb\n",
      "model.layers.22.mlp\n",
      "model.layers.22.mlp.gate_proj\n",
      "model.layers.22.mlp.up_proj\n",
      "model.layers.22.mlp.down_proj\n",
      "model.layers.22.mlp.act_fn\n",
      "model.layers.22.input_layernorm\n",
      "model.layers.22.post_attention_layernorm\n",
      "model.layers.23\n",
      "model.layers.23.self_attn\n",
      "model.layers.23.self_attn.q_proj\n",
      "model.layers.23.self_attn.k_proj\n",
      "model.layers.23.self_attn.v_proj\n",
      "model.layers.23.self_attn.o_proj\n",
      "model.layers.23.self_attn.rotary_emb\n",
      "model.layers.23.mlp\n",
      "model.layers.23.mlp.gate_proj\n",
      "model.layers.23.mlp.up_proj\n",
      "model.layers.23.mlp.down_proj\n",
      "model.layers.23.mlp.act_fn\n",
      "model.layers.23.input_layernorm\n",
      "model.layers.23.post_attention_layernorm\n",
      "model.layers.24\n",
      "model.layers.24.self_attn\n",
      "model.layers.24.self_attn.q_proj\n",
      "model.layers.24.self_attn.k_proj\n",
      "model.layers.24.self_attn.v_proj\n",
      "model.layers.24.self_attn.o_proj\n",
      "model.layers.24.self_attn.rotary_emb\n",
      "model.layers.24.mlp\n",
      "model.layers.24.mlp.gate_proj\n",
      "model.layers.24.mlp.up_proj\n",
      "model.layers.24.mlp.down_proj\n",
      "model.layers.24.mlp.act_fn\n",
      "model.layers.24.input_layernorm\n",
      "model.layers.24.post_attention_layernorm\n",
      "model.layers.25\n",
      "model.layers.25.self_attn\n",
      "model.layers.25.self_attn.q_proj\n",
      "model.layers.25.self_attn.k_proj\n",
      "model.layers.25.self_attn.v_proj\n",
      "model.layers.25.self_attn.o_proj\n",
      "model.layers.25.self_attn.rotary_emb\n",
      "model.layers.25.mlp\n",
      "model.layers.25.mlp.gate_proj\n",
      "model.layers.25.mlp.up_proj\n",
      "model.layers.25.mlp.down_proj\n",
      "model.layers.25.mlp.act_fn\n",
      "model.layers.25.input_layernorm\n",
      "model.layers.25.post_attention_layernorm\n",
      "model.layers.26\n",
      "model.layers.26.self_attn\n",
      "model.layers.26.self_attn.q_proj\n",
      "model.layers.26.self_attn.k_proj\n",
      "model.layers.26.self_attn.v_proj\n",
      "model.layers.26.self_attn.o_proj\n",
      "model.layers.26.self_attn.rotary_emb\n",
      "model.layers.26.mlp\n",
      "model.layers.26.mlp.gate_proj\n",
      "model.layers.26.mlp.up_proj\n",
      "model.layers.26.mlp.down_proj\n",
      "model.layers.26.mlp.act_fn\n",
      "model.layers.26.input_layernorm\n",
      "model.layers.26.post_attention_layernorm\n",
      "model.layers.27\n",
      "model.layers.27.self_attn\n",
      "model.layers.27.self_attn.q_proj\n",
      "model.layers.27.self_attn.k_proj\n",
      "model.layers.27.self_attn.v_proj\n",
      "model.layers.27.self_attn.o_proj\n",
      "model.layers.27.self_attn.rotary_emb\n",
      "model.layers.27.mlp\n",
      "model.layers.27.mlp.gate_proj\n",
      "model.layers.27.mlp.up_proj\n",
      "model.layers.27.mlp.down_proj\n",
      "model.layers.27.mlp.act_fn\n",
      "model.layers.27.input_layernorm\n",
      "model.layers.27.post_attention_layernorm\n",
      "model.norm\n",
      "lm_head\n"
     ]
    }
   ],
   "source": [
    "def print_submodules(model, prefix=''):\n",
    "    for name, submodule in model.named_children():\n",
    "        full_name = f\"{prefix}.{name}\" if prefix else name\n",
    "        print(full_name)\n",
    "        print_submodules(submodule, full_name)\n",
    "\n",
    "# Run the function\n",
    "print_submodules(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u2mlY9pMVtZH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2024.10.7 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# LoRA Adapter 선언\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # 0을 넘는 숫자를 선택하세요. 8, 16, 32, 64, 128이 추천됩니다.\n",
    "     target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",], # target module도 적절하게 조정할 수 있습니다.\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0.1, # 어떤 값이든 사용될 수 있지만, 0으로 최적화되어 있습니다.\n",
    "    bias = \"none\",    # 어떤 값이든 사용될 수 있지만, \"none\"으로 최적화되어 있습니다.\n",
    "    use_gradient_checkpointing = \"unsloth\", # 매우 긴 context에 대해 True 또는 \"unsloth\"를 사용하십시오.\n",
    "    random_state = 42,\n",
    "    use_rslora = False,\n",
    "    loftq_config={\"quantization\": \"4bit\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loDn97x9VtZH"
   },
   "source": [
    "## 3. 데이터셋 전처리\n",
    "데이터셋은 한국어 금융 합성 데이터셋인 `amphora/krx-sample-instruction`를 사용하였고, 데이터셋 템플릿으로는 Alpaca prompt에서 input을 제거한 형태의 프롬프트 템플릿을 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEDXXvLTVtZH"
   },
   "outputs": [],
   "source": [
    "# prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "# ### Instruction:\n",
    "# {}\n",
    "\n",
    "# ### Response:\n",
    "# {}\"\"\"\n",
    "\n",
    "# EOS_TOKEN = tokenizer.eos_token\n",
    "# def formatting_prompts_func(examples):\n",
    "#     instructions = examples[\"prompt\"]\n",
    "#     outputs = examples[\"response\"]\n",
    "#     texts = []\n",
    "#     for instruction, output in zip(instructions, outputs):\n",
    "#         text = prompt_format.format(instruction, output) + EOS_TOKEN # 마지막에 eos token을 추가해줌으로써 모델이 출력을 끝마칠 수 있게 만들어 줍니다.\n",
    "#         texts.append(text)\n",
    "#     return { \"formatted_text\" : texts, }\n",
    "# pass\n",
    "\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"amphora/krx-sample-instructions\", split = \"train\")\n",
    "# dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"csv\", data_files='/krx/formatted_finance_terms_dataset.csv', split=\"train\")\n",
    "\n",
    "def add_eos_token(examples):\n",
    "    # EOS 토큰을 formatted_text 필드의 마지막에 추가\n",
    "    examples[\"formatted_text\"] = examples[\"formatted_text\"] + EOS_TOKEN\n",
    "    return examples\n",
    "# 데이터셋에 EOS 토큰을 추가\n",
    "dataset = dataset.map(add_eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'formatted_text': '### Instruction: This task focuses on understanding key finance terms. For each term, read the context carefully, then answer questions about its definition, typical usage, practical examples, and relevance in finance. Each answer will deepen your understanding of the term’s role in the financial field.\\n\\n    ### Term: 2차 시장(Secondary Market)\\n    \\n    ### Context: 2차 시장은 처음 발행된 증권, 채권 등이 거래되는 발행시장과 구분되며, 이미 발행된 주식들의 거래가 이루어지는 유통시장을 뜻한다. 국내에서는 유가증권시장, 코스닥, 코넥스, 프리보드 시장 등이 2차시장에 해당하며, 외국의 경우\\u2028New York Stock Exachange(NYSE), NASDAQ 등이 있다. 2차 시장에서는 주식이 가장 보편적으로 거래 되며, 주식 외에도 뮤추얼 펀드, 채권과 같은 상품 등도 거래된다. 패니매(Fanni Mae), 프레디맥(Freddie Mac)과 같은 기관들은 2차 시장에서 모기지 관련 상품을 거래하며 모기지 증권을 만든다. \\n\\n1차 시장(Primary Market)에서는 처음 발행된 주식이나 채권을 등의 거래가 이루어지며, 흔히 알려진 거래 형태는 IPO(Initial Public Offering)이다. 이 때 거래된 증권을 후에 재판매하기 위한 거래 시장이 2차 시장이다. 각각의 거래에서 발생한 수익은 거래 당사자에게 돌아가며, 1차 시장에서 IPO 에 참여한 투자은행, 주식 발행 주체가 되는 회사 등은 2차 시장에서의 거래에 관여하지 않는다.\\n    \\n    ### Questions:\\n        1. 이 문장의 요약은 무엇인가요?\\n        - 2차 시장은 이미 발행된 증권과 채권이 거래되는 유통시장으로, 유가증권시장, 코스닥, 프리보드 시장 등이 포함되며, stock 거래가 주를 이룬다.\\n        2. 2차 시장(Secondary Market)의 주요 사용 또는 의미는 무엇인가요?\\n        - 2차 시장은 최초로 발행된 증권이 거래되는 발행시장과 구분되며, 주식, 채권 등 이미 발행된 증권의 유통을 촉진하는 중요한 역할을 한다.\\n        3. 2차 시장(Secondary Market)가 사용되는 방식에 대해 자세히 설명해 주세요.\\n        - 2차 시장에서는 주로 주식 거래가 이루어지며, 뮤추얼 펀드와 채권과 같은 다른 금융 상품도 거래된다. 예를 들어, 패니매와 프레디맥은 모기지 관련 상품을 거래하기 위해 2차 시장을 활용한다.\\n        4. 2차 시장(Secondary Market)는 실제로 어떻게 사용될 수 있나요?\\n        - 투자자는 2차 시장에서 증권 또는 채권을 매매하여 자산을 유동화하거나 이익을 얻을 수 있으며, 기업들도 이 시장을 통해 자본 조달의 기회를 가지게 된다.\\n        5. 2차 시장(Secondary Market)의 중요성은 무엇인가요?\\n        - 2차 시장은 기업들이 자본을 유연하게 조달할 수 있는 기반을 제공하고, 투자자들에게는 유통시장에서 투자한 자산을 쉽게 매매할 수 있는 기회를 제공하여 전체 경제의 유동성을 높이는 역할을 한다.<|im_end|>'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNT3z9nNVtZH"
   },
   "source": [
    "## 4. 모델 학습\n",
    "\n",
    "full train을 위해서는 `num_train_epochs=1`로 설정하고, `max_steps`를 설정하지 않으면 됩니다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "n7K5p11fVtZH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2): 100%|██████████| 804/804 [00:00<00:00, 901.92 examples/s]\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"formatted_text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # True로 설정하면 짧은 텍스트 데이터에 대해서는 더 빠른 학습 속도로를 보여줍니다.\n",
    "    args = TrainingArguments( # TrainingArguments는 자신의 학습 환경과 기호에 따라 적절하게 설정하면 됩니다.\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_ratio = 0.03,\n",
    "        num_train_epochs = 3,\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.001,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 42,\n",
    "        output_dir = \"/krx/save_steps\",\n",
    "        save_steps=100,  # 매 100 스텝마다 체크포인트 저장\n",
    "        save_total_limit=1,  # 최신 1개의 체크포인트만 보관\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "97c2KpwfbNmP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 804 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 2\n",
      "\\        /    Total batch size = 8 | Total steps = 300\n",
      " \"-____-\"     Number of trainable parameters = 40,370,176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 29:16, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.991800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.978500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.910100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.939400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.946400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.922700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.813400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.787200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.792400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.809300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.821700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.784400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.808500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.813200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.700600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.688500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.652700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.699200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.646500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.675100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.671500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.680500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.648200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.664900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZl4bf7ZVtZI"
   },
   "source": [
    "## 5. 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "sHa2tCFgVtZI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    BIC에 대헤서 알려줘.\\n     - BIC은 Bayesian Information Criterion의 약자로, 모델 선택에 사용되는 지표이다. BIC는 데이터와 모델 사이의 적합도를 평가하며, 정보량과 복잡성을 동시에 고려한다. BIC은 AIC(Akaike Information Criterion)와 유사하게 계산되지만, BIC는 log(n)인 대신 log(n) * log(log(n))로 곱해져서 데이터의 크기에 대한 영향을 덜 강하게 반영한다. 이는 BIC가 더 큰 모델에 대한 과적합(overfittingting)을 방지하려는 시도를 나타낸다. 따라서 BIC는 데이터의 크기와 복잡한 모델에 대해 AIC보다 더 나은 모델을 선택하는 데 도움을 준다.\\n\\n    BIC의 수식은 다음과 같다: \\n        BIC = (2k - 2ln(L)) / ln(n)\\n    \\n    여기서,\\n        k : 모델의 파라미터 개수\\n        L : 데이터에 대한 최대 가능 확률\\n        n : 데이터의 샘플 수\\n    \\n    BIC은 데이터']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    \"\"\"\n",
    "    BIC에 대헤서 알려줘.\n",
    "    \"\"\"\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n    다음 중 화폐의 시간가치에 관한 설명으로 옳지 않은 것은 무엇인가?\\n\\nA. 월 복리의 경우, 매월 적용되는 이자율은 연간 명목 이자율을 1/12로 나누어 산출한다.\\nB. 투자 원금 및 기타 조건이 동일할 경우, 단리 방식보다 복리 방식에서 발생하는 이자가 더 크다.\\nC. 일시불로 지급될 금액의 현재 가치는 미래 가치를 일정 기간 동안 할인율을 적용해 산출할 수 있다.\\nD. 1,000,000원을 연 5% 복리로 2년 동안 예치했을 경우, 만기에 받을 세전 이자는 100,000원이다.\\n     - 이 문장의 내용은 옳지 않습니다. 1,000,000원을 연 5% 복리로 2년 동안 예치했을 때, 만기 이자는 원금과 이자를 모두 고려하여 계산해야 합니다. 이 경우, 이자는 11,000,000*(1.05)^2 - 1,000,000 = 110,250,000원 - 1,000,000원 = 100,250원입니다. 따라서 이 문장에서 제시된 이자는 정확하지 않습니다.<|im_end|>']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    \"\"\"\n",
    "    다음 중 화폐의 시간가치에 관한 설명으로 옳지 않은 것은 무엇인가?\n",
    "\n",
    "A. 월 복리의 경우, 매월 적용되는 이자율은 연간 명목 이자율을 1/12로 나누어 산출한다.\n",
    "B. 투자 원금 및 기타 조건이 동일할 경우, 단리 방식보다 복리 방식에서 발생하는 이자가 더 크다.\n",
    "C. 일시불로 지급될 금액의 현재 가치는 미래 가치를 일정 기간 동안 할인율을 적용해 산출할 수 있다.\n",
    "D. 1,000,000원을 연 5% 복리로 2년 동안 예치했을 경우, 만기에 받을 세전 이자는 100,000원이다.\n",
    "    \"\"\"\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n다음 표는 주식 A에 대한 분석 결과입니다. 표를 바탕으로 향후 A의 주가가 상승할지 하락할지 예측하고 [증가] 혹은 [감소] 라고 답변하시요.\\n### 분석:\\n|    | date       |   open |   high |   low |   close |   adj-close |   inc-5 |   inc-10 |   inc-15 |   inc-20 |   inc-25 |   inc-30 |\\n|---:|:-----------|-------:|-------:|------:|--------:|------------:|--------:|---------:|---------:|---------:|---------:|---------:|\\n|  0 | 2020-10-19 |    1.2 |    2.2 |  -0.6 |    -0.1 |        -0.1 |    -1.4 |     -1.2 |     -0.8 |     -2.4 |     -2.4 |     -2.6 |\\n|  1 | 2020-10-20 |    0.6 |    1.2 |  -0.6 |     0.1 |         0.1 |    -0.8 |     -0.8 |     -0.7 |     -2.1 |     -2.3 |     -2.5 |\\n|  2 | 2020-10-21 |    1.6 |    2.3 |  -0   |    -2   |        -2   |     1.3 |      1.2 |      1.3 |      0.3 |     -0.4 |     -0.5 |\\n|  3 | 2020-10-22 |   -2.6 |    0.3 |  -2.9 |     3.2 |         3.2 |    -1.3 |     -1.9 |     -1.8 |     -2.1 |     -3.5 |     -3.3 |\\n|  4 | 2020-10-23 |    1.6 |    1.7 |  -0.8 |    -1   |        -1   |    -0.3 |     -0.9 |     -0.8 |     -0.8 |     -2.3 |     -2.2 |\\n|  5 | 2020-10-26 |    2.6 |    2.9 |  -1.1 |    -3.9 |        -3.9 |     3   |      2.7 |      2.8 |      3.1 |      1.8 |      1.7 |\\n|  6 | 2020-10-27 |    2.5 |    3.2 |  -0.2 |    -3.5 |        -3.5 |     5.2 |      6   |      6.3 |      6.5 |      5.4 |      5.2 |\\n|  7 | 2020-10-28 |    3.3 |    3.9 |  -0.1 |    -4.6 |        -4.6 |     8.1 |     10.1 |     10.6 |     11   |     10.3 |      9.8 |\\n|  8 | 2020-10-29 |   -0.2 |    1.2 |  -1.1 |     0.1 |         0.1 |     5.2 |      8.9 |      9.6 |     10.3 |     10.3 |      9.3 |\\n|  9 | 2020-10-30 |    1.9 |    3.3 |  -1.9 |    -2.6 |        -2.6 |     4.8 |     10.2 |     11.5 |     12.4 |     13   |     11.8 |\\n     ### 질문: 이 데이터의 요약은 무엇인가요?\\n     ### 답변: 주식 A의 가격은 다양한 날짜에 따라 변동하며, 최근에는 주로 상승세를 보이고 있습니다. 그러나 가격 변동성이 크며 일일 거래량이 적은 경향이 있습니다.\\n     ### 질문: 주식 A의 주가가 앞으로 어떻게 움직일 것인가요?\\n     ### 답변: 주식 A의 주가가 상승할 가능성이 높지만, 가격 변동성이 크기 때문에 안정적인 투자 결정을 내릴 때는 주의해야 할 것 같습니다.<|im_end|>']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    \"\"\"\n",
    "다음 표는 주식 A에 대한 분석 결과입니다. 표를 바탕으로 향후 A의 주가가 상승할지 하락할지 예측하고 [증가] 혹은 [감소] 라고 답변하시요.\n",
    "### 분석:\n",
    "|    | date       |   open |   high |   low |   close |   adj-close |   inc-5 |   inc-10 |   inc-15 |   inc-20 |   inc-25 |   inc-30 |\n",
    "|---:|:-----------|-------:|-------:|------:|--------:|------------:|--------:|---------:|---------:|---------:|---------:|---------:|\n",
    "|  0 | 2020-10-19 |    1.2 |    2.2 |  -0.6 |    -0.1 |        -0.1 |    -1.4 |     -1.2 |     -0.8 |     -2.4 |     -2.4 |     -2.6 |\n",
    "|  1 | 2020-10-20 |    0.6 |    1.2 |  -0.6 |     0.1 |         0.1 |    -0.8 |     -0.8 |     -0.7 |     -2.1 |     -2.3 |     -2.5 |\n",
    "|  2 | 2020-10-21 |    1.6 |    2.3 |  -0   |    -2   |        -2   |     1.3 |      1.2 |      1.3 |      0.3 |     -0.4 |     -0.5 |\n",
    "|  3 | 2020-10-22 |   -2.6 |    0.3 |  -2.9 |     3.2 |         3.2 |    -1.3 |     -1.9 |     -1.8 |     -2.1 |     -3.5 |     -3.3 |\n",
    "|  4 | 2020-10-23 |    1.6 |    1.7 |  -0.8 |    -1   |        -1   |    -0.3 |     -0.9 |     -0.8 |     -0.8 |     -2.3 |     -2.2 |\n",
    "|  5 | 2020-10-26 |    2.6 |    2.9 |  -1.1 |    -3.9 |        -3.9 |     3   |      2.7 |      2.8 |      3.1 |      1.8 |      1.7 |\n",
    "|  6 | 2020-10-27 |    2.5 |    3.2 |  -0.2 |    -3.5 |        -3.5 |     5.2 |      6   |      6.3 |      6.5 |      5.4 |      5.2 |\n",
    "|  7 | 2020-10-28 |    3.3 |    3.9 |  -0.1 |    -4.6 |        -4.6 |     8.1 |     10.1 |     10.6 |     11   |     10.3 |      9.8 |\n",
    "|  8 | 2020-10-29 |   -0.2 |    1.2 |  -1.1 |     0.1 |         0.1 |     5.2 |      8.9 |      9.6 |     10.3 |     10.3 |      9.3 |\n",
    "|  9 | 2020-10-30 |    1.9 |    3.3 |  -1.9 |    -2.6 |        -2.6 |     4.8 |     10.2 |     11.5 |     12.4 |     13   |     11.8 |\n",
    "    \"\"\"\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\\n### 질문: 엑세스바이오의 코로나 진단 제품이 주요 매출에 기여한 이유와, 해당 제품들이 미국 시장에서 어떻게 판매되고 있는지를 설명해 주세요.\\n### 선택지: \\nA. 엑세스바이오의 코로나 진단 제품은 바이러스와 관련 없는 일반적인 건강 검진용으로 개발되었으며, 미국 시장에선 주로 소비자 직거래 방식으로 판매되고 있습니다.\\nB. 엑세스바이오의 코로나 진단 제품은 대규모 임상시험을 통해 효과가 입증되어, 기존 진단 키트의 80% 이상을 차지하고 있으며, 주로 소매점에서 판매되고 있습니다.\\nC. 엑세스바이오의 코로나 진단 제품은 에볼라 및 기타 질병 진단에 사용되고 있으며, 미국 시장에서는 주 정부 계약을 통해 독점 판매되고 있습니다.\\nD. 엑세스바이오의 코로나 진단 제품은 COVID-19의 급격한 확산에 대응하여 개발된 신속진단키트로, 주로 연간 매출액에서 99.5%를 차지하고 있습니다. 이 제품들은 미국 시장에서 의료기기 전문 유통사를 통해 판매되고 있으며, 미 FDA로부터 긴급사용승인을 획득한 덕분에 더욱 폭넓은 수요를 만나게 되었습니다.\\n     ### 정답: D. 엑세스바이오의 코로나 진단 제품은 COVID-19의 급격한 확산에 대응하여 개발된 신속진단키트로, 주로 연간 매출액에서 99.5%를 차지하고 있으며, 미국 시장에서 의료기기 전문 유통사를 통해 판매되고 있습니다. 또한 미 FDA로부터 긴급사용승인을 받은 덕분에 많은 수요를 받아들이고 있습니다.<|im_end|>']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    \"\"\"\n",
    "다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
    "### 질문: 엑세스바이오의 코로나 진단 제품이 주요 매출에 기여한 이유와, 해당 제품들이 미국 시장에서 어떻게 판매되고 있는지를 설명해 주세요.\n",
    "### 선택지: \n",
    "A. 엑세스바이오의 코로나 진단 제품은 바이러스와 관련 없는 일반적인 건강 검진용으로 개발되었으며, 미국 시장에선 주로 소비자 직거래 방식으로 판매되고 있습니다.\n",
    "B. 엑세스바이오의 코로나 진단 제품은 대규모 임상시험을 통해 효과가 입증되어, 기존 진단 키트의 80% 이상을 차지하고 있으며, 주로 소매점에서 판매되고 있습니다.\n",
    "C. 엑세스바이오의 코로나 진단 제품은 에볼라 및 기타 질병 진단에 사용되고 있으며, 미국 시장에서는 주 정부 계약을 통해 독점 판매되고 있습니다.\n",
    "D. 엑세스바이오의 코로나 진단 제품은 COVID-19의 급격한 확산에 대응하여 개발된 신속진단키트로, 주로 연간 매출액에서 99.5%를 차지하고 있습니다. 이 제품들은 미국 시장에서 의료기기 전문 유통사를 통해 판매되고 있으며, 미 FDA로부터 긴급사용승인을 획득한 덕분에 더욱 폭넓은 수요를 만나게 되었습니다.\n",
    "    \"\"\"\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\\n### 질문: 다음 중 우리나라 주식시장 매매 제도에 대한 기술로 맞는 것은?\\n### 선택지: \\nA. 개장 시간은 오전 10시다.\\nB. 유가증권시장의 가격 제한폭은 전일 종가 대비 상하 15%이다.\\nC. 코스닥시장에는 가격 제한폭이 없다.\\nD. 점심시간(12~1시)에는 휴장한다.\\nE. 동시호가는 폐장 시간에만 적용한다.\\nF. K-OTC시장의 가격 제한폭은 전일 종가 대비 상하 30%이다.\\nG. K-OTC시장의 운영시간은 09:00부터 16:00까지이다.\\n     ### 정답: B. 유가증권시장의 가격 제한폭은 전일 종가 대비 상하 15%이다.<|im_end|>']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    \"\"\"\n",
    "다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
    "### 질문: 다음 중 우리나라 주식시장 매매 제도에 대한 기술로 맞는 것은?\n",
    "### 선택지: \n",
    "A. 개장 시간은 오전 10시다.\n",
    "B. 유가증권시장의 가격 제한폭은 전일 종가 대비 상하 15%이다.\n",
    "C. 코스닥시장에는 가격 제한폭이 없다.\n",
    "D. 점심시간(12~1시)에는 휴장한다.\n",
    "E. 동시호가는 폐장 시간에만 적용한다.\n",
    "F. K-OTC시장의 가격 제한폭은 전일 종가 대비 상하 30%이다.\n",
    "G. K-OTC시장의 운영시간은 09:00부터 16:00까지이다.\n",
    "    \"\"\"\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n주어진 데이터프레임을 보고 질문에 요구에 알맞는 코드를 선택하시요.\\n### df.head()\\n|    | Symbol    | Series   | Date        |   Prev Close |   Open Price |   High Price |   Low Price |   Last Price |   Close Price |   Average Price |   Total Traded Quantity |    Turnover |   No. of Trades |   Deliverable Qty |   % Dly Qt to Traded Qty |\\n|---:|:----------|:---------|:------------|-------------:|-------------:|-------------:|------------:|-------------:|--------------:|----------------:|------------------------:|------------:|----------------:|------------------:|-------------------------:|\\n|  0 | GODREJIND | EQ       | 15-May-2017 |       564.6  |       581    |       584    |      568.5  |       578.9  |        578.55 |          578.09 |                  797171 | 4.60836e+08 |           21649 |            360927 |                    45.28 |\\n|  1 | GODREJIND | EQ       | 16-May-2017 |       578.55 |       581.45 |       589    |      572.25 |       583.8  |        584.8  |          583.6  |                  500223 | 2.9193e+08  |           17204 |            210364 |                    42.05 |\\n|  2 | GODREJIND | EQ       | 17-May-2017 |       584.8  |       583    |       594    |      576.85 |       584.9  |        588.6  |          588.74 |                  504155 | 2.96815e+08 |            8567 |            261667 |                    51.9  |\\n|  3 | GODREJIND | EQ       | 18-May-2017 |       588.6  |       582    |       588.85 |      571.2  |       572.25 |        574.6  |          580.9  |                  223583 | 1.29879e+08 |            7144 |             99785 |                    44.63 |\\n|  4 | GODREJIND | EQ       | 19-May-2017 |       574.6  |       581    |       585.8  |      567.55 |       579.85 |        578    |          577.31 |                  245436 | 1.41692e+08 |            4969 |             68041 |                    27.72 |\\n\\n### 질문:\\n\"종가\" 열의 평균 값을 계산합니다.\\n\\n### 선택지:\\na) ```python\\ndf[\\'Close Price\\'].mean()\\n```\\nb) ```python\\ndf[\\'Close_Price\\'].mean()\\n```\\nc) ```python\\ndf[\\'Total Traded Quantity\\'].median()\\n```\\nd) ```python\\nsum(df[\\'Close Price\\']) / len(df[\\'Close_Price\\'])\\n```\\n     ### 정답:\\na) ```python\\ndf[\\'Close Price\\'].mean()\\n```<|im_end|>']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    \"\"\"\n",
    "주어진 데이터프레임을 보고 질문에 요구에 알맞는 코드를 선택하시요.\n",
    "### df.head()\n",
    "|    | Symbol    | Series   | Date        |   Prev Close |   Open Price |   High Price |   Low Price |   Last Price |   Close Price |   Average Price |   Total Traded Quantity |    Turnover |   No. of Trades |   Deliverable Qty |   % Dly Qt to Traded Qty |\n",
    "|---:|:----------|:---------|:------------|-------------:|-------------:|-------------:|------------:|-------------:|--------------:|----------------:|------------------------:|------------:|----------------:|------------------:|-------------------------:|\n",
    "|  0 | GODREJIND | EQ       | 15-May-2017 |       564.6  |       581    |       584    |      568.5  |       578.9  |        578.55 |          578.09 |                  797171 | 4.60836e+08 |           21649 |            360927 |                    45.28 |\n",
    "|  1 | GODREJIND | EQ       | 16-May-2017 |       578.55 |       581.45 |       589    |      572.25 |       583.8  |        584.8  |          583.6  |                  500223 | 2.9193e+08  |           17204 |            210364 |                    42.05 |\n",
    "|  2 | GODREJIND | EQ       | 17-May-2017 |       584.8  |       583    |       594    |      576.85 |       584.9  |        588.6  |          588.74 |                  504155 | 2.96815e+08 |            8567 |            261667 |                    51.9  |\n",
    "|  3 | GODREJIND | EQ       | 18-May-2017 |       588.6  |       582    |       588.85 |      571.2  |       572.25 |        574.6  |          580.9  |                  223583 | 1.29879e+08 |            7144 |             99785 |                    44.63 |\n",
    "|  4 | GODREJIND | EQ       | 19-May-2017 |       574.6  |       581    |       585.8  |      567.55 |       579.85 |        578    |          577.31 |                  245436 | 1.41692e+08 |            4969 |             68041 |                    27.72 |\n",
    "\n",
    "### 질문:\n",
    "\"종가\" 열의 평균 값을 계산합니다.\n",
    "\n",
    "### 선택지:\n",
    "a) ```python\n",
    "df['Close Price'].mean()\n",
    "```\n",
    "b) ```python\n",
    "df['Close_Price'].mean()\n",
    "```\n",
    "c) ```python\n",
    "df['Total Traded Quantity'].median()\n",
    "```\n",
    "d) ```python\n",
    "sum(df['Close Price']) / len(df['Close_Price'])\n",
    "```\n",
    "    \"\"\"\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ9S7MWeVtZI"
   },
   "source": [
    "## 6. 모델 저장 및 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3DsyXPKqVtZI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 127.18 out of 251.62 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 23/28 [00:00<00:00, 47.49it/s]We will save to Disk and not RAM now.\n",
      "100%|██████████| 28/28 [00:01<00:00, 26.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n",
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 127.16 out of 251.62 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 27.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving to organization with address KR-X-AI/krx-qwen2-7b-instruct-v2\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Unsloth: Saving to organization with address KR-X-AI/krx-qwen2-7b-instruct-v2\n",
      "Unsloth: Uploading all files... Please wait...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 8.19k/4.88G [00:00<17:41:16, 76.6kB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 1.70M/4.88G [00:00<11:43, 6.93MB/s]   \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 2.29M/4.88G [00:00<29:54, 2.72MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|          | 4.72M/4.88G [00:00<13:12, 6.15MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 13.0M/4.88G [00:01<04:46, 17.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 20.3M/4.88G [00:02<08:19, 9.73MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 22.4M/4.88G [00:02<08:31, 9.50MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   0%|          | 23.9M/4.88G [00:02<08:28, 9.54MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 26.0M/4.88G [00:03<07:51, 10.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 27.3M/4.88G [00:03<08:16, 9.77MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 29.5M/4.88G [00:03<07:08, 11.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 31.7M/4.88G [00:03<06:17, 12.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 33.2M/4.88G [00:04<13:16, 6.08MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|          | 36.2M/4.88G [00:04<09:58, 8.09MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 37.4M/4.88G [00:04<09:44, 8.28MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 38.6M/4.88G [00:04<09:41, 8.32MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 39.7M/4.88G [00:04<09:39, 8.35MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 42.1M/4.88G [00:04<08:32, 9.43MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 43.3M/4.88G [00:04<08:01, 10.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 45.7M/4.88G [00:05<06:24, 12.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 47.8M/4.88G [00:05<06:29, 12.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 53.5M/4.88G [00:06<09:06, 8.83MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 54.8M/4.88G [00:06<08:55, 9.01MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 56.1M/4.88G [00:06<08:50, 9.09MB/s]\n",
      "model-00001-of-00004.safetensors:   1%|          | 57.3M/4.88G [00:06<08:53, 9.04MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|          | 60.9M/4.88G [00:06<07:05, 11.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 63.9M/4.88G [00:07<06:26, 12.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 65.2M/4.88G [00:07<11:52, 6.76MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 68.2M/4.88G [00:07<09:17, 8.63MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 69.6M/4.88G [00:07<09:02, 8.86MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 71.8M/4.88G [00:08<08:07, 9.86MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   1%|▏         | 72.9M/4.88G [00:08<07:56, 10.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 78.0M/4.88G [00:08<06:52, 11.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 80.0M/4.88G [00:09<13:02, 6.13MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 84.5M/4.88G [00:09<08:11, 9.75MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 87.3M/4.88G [00:09<07:41, 10.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 89.2M/4.88G [00:09<07:49, 10.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 91.5M/4.88G [00:10<09:08, 8.73MB/s]\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 94.1M/4.88G [00:10<07:25, 10.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 96.0M/4.88G [00:11<13:46, 5.78MB/s]\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 101M/4.88G [00:11<07:20, 10.8MB/s] \n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 104M/4.88G [00:11<05:53, 13.5MB/s]\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 109M/4.88G [00:11<04:15, 18.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 112M/4.88G [00:11<05:27, 14.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 116M/4.88G [00:11<04:42, 16.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   2%|▏         | 118M/4.88G [00:12<04:41, 16.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 122M/4.88G [00:12<07:03, 11.2MB/s]\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 124M/4.88G [00:12<06:45, 11.7MB/s]\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 125M/4.88G [00:12<06:46, 11.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 127M/4.88G [00:12<06:48, 11.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 137M/4.88G [00:13<04:22, 18.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 144M/4.88G [00:14<04:54, 16.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 149M/4.88G [00:14<04:24, 17.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 151M/4.88G [00:14<04:26, 17.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 157M/4.88G [00:15<06:18, 12.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 158M/4.88G [00:15<06:18, 12.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   3%|▎         | 167M/4.88G [00:15<05:36, 14.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 171M/4.88G [00:16<04:40, 16.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▎         | 176M/4.88G [00:16<05:14, 15.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 187M/4.88G [00:16<03:12, 24.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 192M/4.88G [00:17<04:15, 18.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 196M/4.88G [00:17<04:19, 18.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 199M/4.88G [00:17<05:32, 14.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 201M/4.88G [00:17<05:23, 14.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 203M/4.88G [00:17<05:53, 13.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 206M/4.88G [00:18<04:58, 15.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 208M/4.88G [00:18<10:07, 7.69MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 213M/4.88G [00:19<08:33, 9.08MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 215M/4.88G [00:19<07:21, 10.6MB/s]\n",
      "model-00001-of-00004.safetensors:   4%|▍         | 217M/4.88G [00:19<07:04, 11.0MB/s]\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 220M/4.88G [00:19<05:21, 14.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 232M/4.88G [00:20<03:56, 19.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▍         | 240M/4.88G [00:20<04:32, 17.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 251M/4.88G [00:20<02:47, 27.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 256M/4.88G [00:21<03:50, 20.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   5%|▌         | 267M/4.88G [00:21<02:30, 30.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 273M/4.88G [00:21<03:13, 23.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 280M/4.88G [00:22<02:33, 29.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 288M/4.88G [00:22<03:03, 25.0MB/s]\n",
      "model-00001-of-00004.safetensors:   6%|▌         | 302M/4.88G [00:22<02:02, 37.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▋         | 314M/4.88G [00:23<02:23, 31.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 332M/4.88G [00:23<02:24, 31.4MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 349M/4.88G [00:24<02:12, 34.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   7%|▋         | 363M/4.88G [00:24<02:08, 35.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 369M/4.88G [00:25<02:40, 28.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 374M/4.88G [00:25<02:30, 30.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 379M/4.88G [00:25<02:13, 33.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 394M/4.88G [00:25<02:14, 33.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▊         | 400M/4.88G [00:26<03:15, 22.9MB/s]\n",
      "model-00001-of-00004.safetensors:   9%|▊         | 416M/4.88G [00:26<01:59, 37.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 432M/4.88G [00:27<02:01, 36.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 438M/4.88G [00:27<02:56, 25.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 448M/4.88G [00:28<03:03, 24.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:   9%|▉         | 462M/4.88G [00:28<02:01, 36.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 468M/4.88G [00:28<02:41, 27.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 473M/4.88G [00:28<02:59, 24.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 477M/4.88G [00:29<04:13, 17.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 480M/4.88G [00:29<03:55, 18.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▉         | 483M/4.88G [00:30<06:41, 10.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 495M/4.88G [00:30<03:33, 20.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 499M/4.88G [00:30<04:13, 17.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  10%|█         | 506M/4.88G [00:30<03:11, 22.9MB/s]\n",
      "model-00001-of-00004.safetensors:  10%|█         | 512M/4.88G [00:31<02:38, 27.5MB/s]\n",
      "model-00001-of-00004.safetensors:  11%|█         | 527M/4.88G [00:31<02:13, 32.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█         | 532M/4.88G [00:31<02:45, 26.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█         | 541M/4.88G [00:31<02:02, 35.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|█         | 546M/4.88G [00:32<02:48, 25.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 553M/4.88G [00:32<02:16, 31.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  11%|█▏        | 560M/4.88G [00:32<02:50, 25.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 574M/4.88G [00:32<01:47, 40.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 590M/4.88G [00:33<02:05, 34.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 597M/4.88G [00:34<02:36, 27.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  12%|█▏        | 607M/4.88G [00:34<01:53, 37.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 614M/4.88G [00:34<03:01, 23.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 620M/4.88G [00:34<02:37, 27.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 625M/4.88G [00:35<03:20, 21.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 631M/4.88G [00:35<02:47, 25.4MB/s]\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 635M/4.88G [00:35<02:36, 27.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|█▎        | 648M/4.88G [00:36<03:08, 22.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▎        | 668M/4.88G [00:36<02:04, 33.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 674M/4.88G [00:37<02:36, 26.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 682M/4.88G [00:37<02:09, 32.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 688M/4.88G [00:37<03:17, 21.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 699M/4.88G [00:37<02:16, 30.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|█▍        | 705M/4.88G [00:38<02:42, 25.7MB/s]\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 712M/4.88G [00:38<02:13, 31.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 717M/4.88G [00:38<02:01, 34.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▍        | 722M/4.88G [00:38<02:51, 24.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 734M/4.88G [00:39<01:51, 37.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 740M/4.88G [00:39<02:45, 25.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  15%|█▌        | 751M/4.88G [00:39<01:56, 35.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 757M/4.88G [00:40<02:37, 26.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 762M/4.88G [00:40<02:30, 27.3MB/s]\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 767M/4.88G [00:40<02:19, 29.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 771M/4.88G [00:40<03:22, 20.3MB/s]\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 781M/4.88G [00:40<02:27, 27.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▌        | 785M/4.88G [00:41<05:13, 13.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 799M/4.88G [00:41<02:38, 25.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|█▋        | 804M/4.88G [00:42<02:54, 23.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 816M/4.88G [00:42<02:05, 32.3MB/s]\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 820M/4.88G [00:42<02:49, 23.9MB/s]\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 826M/4.88G [00:42<02:26, 27.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 832M/4.88G [00:43<02:05, 32.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 836M/4.88G [00:43<03:13, 20.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 839M/4.88G [00:43<03:08, 21.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  17%|█▋        | 844M/4.88G [00:43<02:41, 25.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 861M/4.88G [00:44<02:17, 29.3MB/s]\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 865M/4.88G [00:44<03:22, 19.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 873M/4.88G [00:44<02:25, 27.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 878M/4.88G [00:45<02:12, 30.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 882M/4.88G [00:45<02:55, 22.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  18%|█▊        | 888M/4.88G [00:45<02:24, 27.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▊        | 909M/4.88G [00:46<01:48, 36.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 927M/4.88G [00:46<01:37, 40.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 934M/4.88G [00:46<02:14, 29.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  19%|█▉        | 944M/4.88G [00:47<02:36, 25.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 957M/4.88G [00:47<01:48, 36.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|█▉        | 971M/4.88G [00:48<01:50, 35.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 977M/4.88G [00:48<02:20, 27.8MB/s]\n",
      "model-00001-of-00004.safetensors:  20%|██        | 984M/4.88G [00:48<01:55, 33.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|██        | 989M/4.88G [00:48<01:50, 35.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  20%|██        | 994M/4.88G [00:49<02:52, 22.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.00G/4.88G [00:49<01:57, 32.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.02G/4.88G [00:49<02:04, 31.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|██        | 1.02G/4.88G [00:50<03:07, 20.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.04G/4.88G [00:50<01:58, 32.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  21%|██▏       | 1.04G/4.88G [00:50<02:24, 26.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.05G/4.88G [00:50<01:54, 33.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.07G/4.88G [00:51<01:57, 32.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.07G/4.88G [00:51<02:46, 22.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.09G/4.88G [00:52<01:51, 34.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|██▏       | 1.10G/4.88G [00:52<02:03, 30.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.10G/4.88G [00:53<02:33, 24.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.12G/4.88G [00:53<01:43, 36.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.13G/4.88G [00:53<01:41, 36.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  23%|██▎       | 1.14G/4.88G [00:54<02:22, 26.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▎       | 1.15G/4.88G [00:54<01:36, 38.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.17G/4.88G [00:54<01:35, 38.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.18G/4.88G [00:55<01:44, 35.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  24%|██▍       | 1.19G/4.88G [00:55<02:20, 26.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.20G/4.88G [00:55<01:43, 35.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.21G/4.88G [00:56<01:38, 37.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|██▍       | 1.22G/4.88G [00:56<03:00, 20.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.23G/4.88G [00:57<01:58, 30.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|██▌       | 1.24G/4.88G [00:57<02:29, 24.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.25G/4.88G [00:57<02:05, 28.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.25G/4.88G [00:57<02:29, 24.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.26G/4.88G [00:58<02:03, 29.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.26G/4.88G [00:58<02:56, 20.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  26%|██▌       | 1.28G/4.88G [00:58<01:41, 35.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.29G/4.88G [00:59<01:28, 40.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.31G/4.88G [00:59<02:10, 27.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.32G/4.88G [01:00<02:11, 27.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  27%|██▋       | 1.34G/4.88G [01:00<01:51, 31.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.34G/4.88G [01:01<02:35, 22.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.36G/4.88G [01:01<01:35, 36.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.37G/4.88G [01:02<02:27, 23.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.37G/4.88G [01:03<04:42, 12.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.38G/4.88G [01:03<04:41, 12.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  28%|██▊       | 1.39G/4.88G [01:04<03:50, 15.1MB/s]\n",
      "model-00001-of-00004.safetensors:  29%|██▊       | 1.39G/4.88G [01:04<04:04, 14.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.41G/4.88G [01:05<02:25, 23.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.41G/4.88G [01:05<03:43, 15.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.42G/4.88G [01:06<02:15, 25.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  29%|██▉       | 1.44G/4.88G [01:06<02:04, 27.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|██▉       | 1.45G/4.88G [01:07<01:37, 35.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.47G/4.88G [01:07<01:30, 37.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  30%|███       | 1.48G/4.88G [01:08<01:54, 29.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.49G/4.88G [01:08<02:28, 22.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.50G/4.88G [01:08<01:46, 31.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.50G/4.88G [01:09<02:21, 23.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███       | 1.51G/4.88G [01:09<01:50, 30.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███▏      | 1.53G/4.88G [01:09<01:40, 33.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  31%|███▏      | 1.53G/4.88G [01:09<01:28, 37.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.55G/4.88G [01:10<02:06, 26.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.55G/4.88G [01:10<02:32, 21.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.56G/4.88G [01:10<01:38, 33.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.57G/4.88G [01:11<02:09, 25.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  32%|███▏      | 1.58G/4.88G [01:11<01:26, 38.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.60G/4.88G [01:12<02:00, 27.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.61G/4.88G [01:13<02:27, 22.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.62G/4.88G [01:13<02:34, 21.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  33%|███▎      | 1.62G/4.88G [01:13<01:57, 27.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▎      | 1.64G/4.88G [01:14<01:38, 32.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.65G/4.88G [01:14<02:22, 22.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.66G/4.88G [01:14<01:40, 32.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|███▍      | 1.67G/4.88G [01:15<02:17, 23.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.68G/4.88G [01:15<02:04, 25.6MB/s]\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.69G/4.88G [01:15<01:43, 30.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.69G/4.88G [01:15<01:36, 33.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▍      | 1.70G/4.88G [01:16<02:07, 25.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.71G/4.88G [01:16<01:26, 36.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.72G/4.88G [01:16<02:00, 26.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  35%|███▌      | 1.73G/4.88G [01:16<01:25, 36.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.74G/4.88G [01:17<01:23, 37.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.75G/4.88G [01:17<01:48, 28.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.75G/4.88G [01:17<01:41, 30.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▌      | 1.76G/4.88G [01:18<02:04, 25.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.77G/4.88G [01:18<01:30, 34.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.77G/4.88G [01:18<01:23, 37.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  36%|███▋      | 1.78G/4.88G [01:19<02:52, 18.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.79G/4.88G [01:19<02:12, 23.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.79G/4.88G [01:19<02:34, 20.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.80G/4.88G [01:19<01:40, 30.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.88G [01:20<01:31, 33.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|███▋      | 1.82G/4.88G [01:20<02:03, 24.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.83G/4.88G [01:20<01:38, 31.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.84G/4.88G [01:21<01:22, 37.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.85G/4.88G [01:21<01:47, 28.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.85G/4.88G [01:21<01:19, 38.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.86G/4.88G [01:21<01:49, 27.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.87G/4.88G [01:21<01:20, 37.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  38%|███▊      | 1.88G/4.88G [01:22<01:49, 27.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  39%|███▊      | 1.89G/4.88G [01:22<01:20, 37.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.90G/4.88G [01:23<01:26, 34.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.91G/4.88G [01:23<02:16, 21.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  39%|███▉      | 1.91G/4.88G [01:23<01:50, 26.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.93G/4.88G [01:24<01:33, 31.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.94G/4.88G [01:24<02:01, 24.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|███▉      | 1.95G/4.88G [01:24<01:30, 32.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|████      | 1.95G/4.88G [01:24<01:20, 36.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|████      | 1.96G/4.88G [01:25<02:30, 19.4MB/s]\n",
      "model-00001-of-00004.safetensors:  40%|████      | 1.96G/4.88G [01:25<02:03, 23.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  40%|████      | 1.97G/4.88G [01:25<02:30, 19.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 1.98G/4.88G [01:26<01:28, 32.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 1.99G/4.88G [01:26<02:00, 24.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.00G/4.88G [01:26<01:25, 33.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████      | 2.00G/4.88G [01:27<01:44, 27.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  41%|████▏     | 2.01G/4.88G [01:27<01:19, 36.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.03G/4.88G [01:27<01:18, 36.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.04G/4.88G [01:28<01:29, 31.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.05G/4.88G [01:28<01:20, 35.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.05G/4.88G [01:28<02:00, 23.5MB/s]\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.06G/4.88G [01:28<01:23, 33.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  42%|████▏     | 2.07G/4.88G [01:29<01:39, 28.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.08G/4.88G [01:29<01:22, 33.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.09G/4.88G [01:29<01:09, 40.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.11G/4.88G [01:30<01:15, 36.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.11G/4.88G [01:30<01:53, 24.4MB/s]\n",
      "model-00001-of-00004.safetensors:  43%|████▎     | 2.12G/4.88G [01:30<01:36, 28.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|████▎     | 2.13G/4.88G [01:30<01:23, 33.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.14G/4.88G [01:31<01:31, 29.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.15G/4.88G [01:31<01:18, 34.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.16G/4.88G [01:32<01:47, 25.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  44%|████▍     | 2.17G/4.88G [01:32<01:20, 33.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▍     | 2.19G/4.88G [01:33<01:12, 37.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.20G/4.88G [01:33<01:36, 27.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.20G/4.88G [01:33<01:23, 32.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  45%|████▌     | 2.21G/4.88G [01:34<01:57, 22.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.22G/4.88G [01:34<01:16, 34.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.24G/4.88G [01:34<01:16, 34.6MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.24G/4.88G [01:35<01:37, 27.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▌     | 2.25G/4.88G [01:35<01:12, 36.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.26G/4.88G [01:35<01:27, 29.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  46%|████▋     | 2.26G/4.88G [01:35<01:21, 32.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.29G/4.88G [01:36<01:15, 34.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.29G/4.88G [01:36<01:36, 26.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.30G/4.88G [01:36<01:20, 32.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.31G/4.88G [01:37<02:09, 19.8MB/s]\n",
      "model-00001-of-00004.safetensors:  47%|████▋     | 2.31G/4.88G [01:37<01:35, 26.9MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.32G/4.88G [01:38<02:27, 17.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.33G/4.88G [01:38<01:31, 27.8MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.35G/4.88G [01:39<01:25, 29.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.36G/4.88G [01:39<01:40, 25.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  48%|████▊     | 2.37G/4.88G [01:39<01:13, 34.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.38G/4.88G [01:40<01:07, 37.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.40G/4.88G [01:40<01:22, 29.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.41G/4.88G [01:41<01:56, 21.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  49%|████▉     | 2.41G/4.88G [01:41<01:34, 26.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.42G/4.88G [01:41<02:02, 20.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.43G/4.88G [01:42<01:19, 30.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|████▉     | 2.44G/4.88G [01:42<01:43, 23.5MB/s]\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.45G/4.88G [01:42<01:15, 32.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.45G/4.88G [01:42<01:28, 27.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  50%|█████     | 2.46G/4.88G [01:43<01:09, 34.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.47G/4.88G [01:43<01:32, 26.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.48G/4.88G [01:43<01:07, 35.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|█████     | 2.49G/4.88G [01:44<01:02, 37.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.50G/4.88G [01:44<01:25, 27.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  51%|█████▏    | 2.51G/4.88G [01:44<01:16, 30.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.53G/4.88G [01:45<01:00, 38.7MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.54G/4.88G [01:45<01:02, 37.2MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|█████▏    | 2.56G/4.88G [01:46<01:08, 33.8MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.56G/4.88G [01:46<01:25, 27.0MB/s]\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.57G/4.88G [01:46<01:08, 33.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.58G/4.88G [01:47<01:30, 25.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.59G/4.88G [01:47<01:03, 36.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.59G/4.88G [01:47<01:20, 28.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.60G/4.88G [01:47<01:16, 29.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  53%|█████▎    | 2.60G/4.88G [01:47<01:09, 32.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▎    | 2.62G/4.88G [01:48<00:59, 38.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.63G/4.88G [01:48<01:20, 27.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.64G/4.88G [01:48<01:08, 32.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.64G/4.88G [01:49<01:44, 21.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.65G/4.88G [01:49<01:22, 27.1MB/s]\n",
      "model-00001-of-00004.safetensors:  54%|█████▍    | 2.65G/4.88G [01:49<01:07, 33.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.66G/4.88G [01:50<01:42, 21.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▍    | 2.67G/4.88G [01:50<01:20, 27.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.69G/4.88G [01:50<01:02, 35.3MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.70G/4.88G [01:51<01:01, 35.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  55%|█████▌    | 2.71G/4.88G [01:56<08:28, 4.27MB/s]\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.71G/4.88G [01:56<06:52, 5.25MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▌    | 2.73G/4.88G [01:57<03:27, 10.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.75G/4.88G [01:57<02:06, 16.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|█████▋    | 2.75G/4.88G [01:58<02:08, 16.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.76G/4.88G [01:58<01:26, 24.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.78G/4.88G [01:58<01:07, 31.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|█████▋    | 2.80G/4.88G [01:59<00:58, 35.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.82G/4.88G [01:59<00:56, 36.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.82G/4.88G [02:00<01:16, 27.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.83G/4.88G [02:00<00:58, 35.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|█████▊    | 2.85G/4.88G [02:00<00:57, 35.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▊    | 2.86G/4.88G [02:01<00:54, 36.9MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.87G/4.88G [02:01<01:10, 28.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.88G/4.88G [02:01<00:55, 36.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|█████▉    | 2.89G/4.88G [02:02<00:58, 34.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.91G/4.88G [02:02<01:02, 31.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|█████▉    | 2.92G/4.88G [02:03<01:17, 25.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 2.94G/4.88G [02:04<01:04, 30.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  60%|██████    | 2.94G/4.88G [02:04<01:20, 23.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 2.96G/4.88G [02:04<00:53, 35.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 2.96G/4.88G [02:05<01:09, 27.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████    | 2.97G/4.88G [02:05<00:51, 37.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|██████▏   | 2.99G/4.88G [02:05<00:52, 35.7MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  61%|██████▏   | 2.99G/4.88G [02:06<01:15, 24.9MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.01G/4.88G [02:06<00:51, 36.5MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.01G/4.88G [02:06<01:03, 29.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.02G/4.88G [02:07<01:28, 20.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  62%|██████▏   | 3.04G/4.88G [02:07<01:00, 30.4MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.05G/4.88G [02:08<00:55, 32.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.06G/4.88G [02:08<01:10, 25.8MB/s]\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.07G/4.88G [02:08<00:57, 31.7MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.08G/4.88G [02:08<01:08, 26.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  63%|██████▎   | 3.09G/4.88G [02:09<00:48, 37.2MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▎   | 3.10G/4.88G [02:09<00:45, 38.8MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.11G/4.88G [02:10<01:05, 26.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.12G/4.88G [02:10<01:12, 24.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.13G/4.88G [02:10<00:53, 33.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  64%|██████▍   | 3.15G/4.88G [02:11<01:03, 27.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.15G/4.88G [02:11<01:10, 24.5MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.16G/4.88G [02:11<00:56, 30.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|██████▍   | 3.17G/4.88G [02:12<01:08, 24.8MB/s]\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.18G/4.88G [02:12<00:50, 33.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.18G/4.88G [02:12<01:06, 25.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|██████▌   | 3.19G/4.88G [02:12<00:50, 33.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.20G/4.88G [02:13<01:05, 25.6MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.21G/4.88G [02:13<00:49, 33.4MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.21G/4.88G [02:13<00:45, 36.4MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.22G/4.88G [02:13<01:02, 26.5MB/s]\n",
      "model-00001-of-00004.safetensors:  66%|██████▌   | 3.23G/4.88G [02:14<00:45, 36.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  66%|██████▋   | 3.24G/4.88G [02:14<01:01, 26.5MB/s]\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.25G/4.88G [02:14<00:46, 35.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.25G/4.88G [02:15<01:09, 23.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.26G/4.88G [02:15<00:51, 31.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.28G/4.88G [02:15<00:43, 36.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|██████▋   | 3.28G/4.88G [02:16<01:03, 25.2MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.29G/4.88G [02:16<00:47, 33.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.30G/4.88G [02:16<01:05, 24.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.31G/4.88G [02:16<00:45, 34.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.32G/4.88G [02:18<02:01, 12.8MB/s]\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.32G/4.88G [02:18<01:31, 17.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.33G/4.88G [02:18<01:40, 15.5MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  68%|██████▊   | 3.34G/4.88G [02:18<01:05, 23.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  69%|██████▊   | 3.34G/4.88G [02:19<01:14, 20.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  69%|██████▊   | 3.35G/4.88G [02:19<01:01, 24.7MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.36G/4.88G [02:19<00:57, 26.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.36G/4.88G [02:19<01:15, 20.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.37G/4.88G [02:20<00:47, 31.9MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.38G/4.88G [02:20<00:55, 27.1MB/s]\n",
      "model-00001-of-00004.safetensors:  69%|██████▉   | 3.38G/4.88G [02:20<00:51, 28.8MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.39G/4.88G [02:20<01:07, 22.0MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|██████▉   | 3.41G/4.88G [02:21<00:37, 39.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.42G/4.88G [02:21<00:45, 32.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.42G/4.88G [02:21<00:41, 35.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.43G/4.88G [02:21<01:01, 23.8MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.43G/4.88G [02:22<00:49, 29.3MB/s]\n",
      "model-00001-of-00004.safetensors:  70%|███████   | 3.44G/4.88G [02:22<00:47, 30.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.44G/4.88G [02:22<01:08, 21.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.45G/4.88G [02:22<00:46, 30.5MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.45G/4.88G [02:22<00:42, 33.9MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.46G/4.88G [02:23<01:03, 22.5MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.47G/4.88G [02:23<00:47, 29.6MB/s]\n",
      "model-00001-of-00004.safetensors:  71%|███████   | 3.47G/4.88G [02:23<00:42, 33.1MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  71%|███████▏  | 3.48G/4.88G [02:23<00:47, 29.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.50G/4.88G [02:24<00:34, 40.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.51G/4.88G [02:24<00:50, 27.3MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.51G/4.88G [02:25<00:48, 28.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  72%|███████▏  | 3.53G/4.88G [02:25<00:45, 29.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.55G/4.88G [02:26<00:57, 23.2MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.55G/4.88G [02:27<01:02, 21.3MB/s]\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.56G/4.88G [02:27<00:55, 23.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.58G/4.88G [02:27<00:48, 26.8MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  73%|███████▎  | 3.58G/4.88G [02:27<00:41, 31.5MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▎  | 3.59G/4.88G [02:28<00:42, 30.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.61G/4.88G [02:28<00:33, 37.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.62G/4.88G [02:29<00:43, 28.7MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  74%|███████▍  | 3.63G/4.88G [02:29<00:30, 41.2MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▍  | 3.64G/4.88G [02:30<00:48, 25.7MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.66G/4.88G [02:30<00:33, 36.1MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.67G/4.88G [02:31<00:57, 21.1MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  75%|███████▌  | 3.68G/4.88G [02:31<00:50, 24.0MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.69G/4.88G [02:32<00:38, 31.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███████▌  | 3.71G/4.88G [02:32<00:39, 29.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  76%|███████▋  | 3.72G/4.88G [02:33<00:40, 28.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.74G/4.88G [02:33<00:32, 34.6MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.74G/4.88G [02:33<00:30, 37.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.75G/4.88G [02:34<00:42, 26.4MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.76G/4.88G [02:34<00:32, 34.4MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.76G/4.88G [02:34<00:43, 25.6MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.77G/4.88G [02:34<00:36, 30.6MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  77%|███████▋  | 3.78G/4.88G [02:35<00:45, 24.3MB/s]\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.78G/4.88G [02:35<00:33, 33.1MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.80G/4.88G [02:35<00:32, 33.3MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███████▊  | 3.82G/4.88G [02:36<00:28, 37.0MB/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "model-00004-of-00004.safetensors: 100%|██████████| 1.09G/1.09G [02:37<00:00, 6.94MB/s]\n",
      "\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.85G/4.88G [02:37<00:41, 25.0MB/s]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.86G/4.88G [02:38<00:50, 20.4MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.86G/4.88G [02:38<00:41, 24.5MB/s]\n",
      "model-00001-of-00004.safetensors:  79%|███████▉  | 3.87G/4.88G [02:38<00:36, 27.4MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.89G/4.88G [02:39<00:37, 26.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|███████▉  | 3.90G/4.88G [02:39<00:33, 28.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|████████  | 3.91G/4.88G [02:40<00:38, 24.9MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 3.93G/4.88G [02:41<00:28, 33.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 3.95G/4.88G [02:41<00:24, 38.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  81%|████████  | 3.96G/4.88G [02:42<00:33, 27.1MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 3.98G/4.88G [02:42<00:30, 29.8MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.00G/4.88G [02:43<00:25, 35.0MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.02G/4.88G [02:43<00:22, 38.6MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████████▏ | 4.02G/4.88G [02:44<00:29, 28.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.05G/4.88G [02:44<00:22, 36.3MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████████▎ | 4.06G/4.88G [02:45<00:20, 39.3MB/s]\n",
      "model-00001-of-00004.safetensors:  84%|████████▎ | 4.08G/4.88G [02:46<00:26, 30.5MB/s]\n",
      "\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████████▍ | 4.09G/4.88G [02:46<00:34, 22.8MB/s]\n",
      "model-00003-of-00004.safetensors: 100%|██████████| 4.33G/4.33G [02:47<00:00, 25.9MB/s]\n",
      "model-00001-of-00004.safetensors: 100%|██████████| 4.88G/4.88G [03:16<00:00, 24.8MB/s]\n",
      "\n",
      "\n",
      "model-00002-of-00004.safetensors: 100%|██████████| 4.93G/4.93G [03:29<00:00, 23.6MB/s]\n",
      "\n",
      "\n",
      "Upload 4 LFS files: 100%|██████████| 4/4 [03:29<00:00, 52.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/None/krx-qwen2-7b-instruct-v2\n"
     ]
    }
   ],
   "source": [
    "# LoRA Adapter 저장\n",
    "model.save_pretrained(\"lora_model\")\n",
    "tokenizer.save_pretrained(\"lora_model\")\n",
    "\n",
    "# Merged model 저장 및 업로드\n",
    "model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "model.push_to_hub_merged(\"krx-qwen2-7b-instruct-v2\", tokenizer, save_method = \"merged_16bit\", token = \"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\") # 개인 huggingface token을 사용하여 업로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAJJR1YVLYdg"
   },
   "source": [
    "## 참고자료\n",
    "\n",
    "- [Unsloth GitHub](https://github.com/unslothai/unsloth)\n",
    "- [Unsloth Docs](https://docs.unsloth.ai/)\n",
    "- [Unsloth Meta-Llama-3.1-8B Finetuning Tutorial](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing)\n",
    "- [Huggingface PEFT](https://github.com/huggingface/peft)\n",
    "- [Huggingface TRL](https://github.com/huggingface/trl)\n",
    "- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)\n",
    "- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)\n",
    "- [FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning](https://arxiv.org/abs/2307.08691)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
