{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Cartinoe5930/raw_text_synthetic_dataset_50k\", split = \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 역색인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndex:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.index = defaultdict(dict)\n",
    "        self.kiwi = Kiwi()\n",
    "        self.document_lengths = {}\n",
    "        self.total_documents = 0\n",
    "        self.average_document_length = 0\n",
    "        self.documents = {}\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        return [token.form for token in self.kiwi.tokenize(text)]\n",
    "\n",
    "    def add_document(self, doc_id, question, answer):\n",
    "        tokens = self.tokenize(question)\n",
    "        self.document_lengths[doc_id] = len(tokens)\n",
    "        self.total_documents += 1\n",
    "        self.documents[doc_id] = {'question': question, 'answer': answer}\n",
    "\n",
    "        for token in set(tokens):\n",
    "            if doc_id not in self.index[token]:\n",
    "                self.index[token][doc_id] = 0\n",
    "            self.index[token][doc_id] += tokens.count(token)\n",
    "\n",
    "        self.average_document_length = sum(self.document_lengths.values()) / self.total_documents\n",
    "\n",
    "    def calculate_bm25_score(self, query_tokens, doc_id):\n",
    "        k1 = 1.5\n",
    "        b = 0.75\n",
    "        score = 0\n",
    "\n",
    "        for token in query_tokens:\n",
    "            if token not in self.index or doc_id not in self.index[token]:\n",
    "                continue\n",
    "\n",
    "            tf = self.index[token][doc_id]\n",
    "            df = len(self.index[token])\n",
    "            idf = math.log((self.total_documents - df + 0.5) / (df + 0.5) + 1)\n",
    "\n",
    "            numerator = tf * (k1 + 1)\n",
    "            denominator = tf + k1 * (1 - b + b * self.document_lengths[doc_id] / self.average_document_length)\n",
    "            score += idf * numerator / denominator\n",
    "\n",
    "        return score\n",
    "\n",
    "    def search(self, query, k=5):\n",
    "        query_tokens = self.tokenize(query)\n",
    "        scores = defaultdict(float)\n",
    "\n",
    "        for token in query_tokens:\n",
    "            if token in self.index:\n",
    "                for doc_id in self.index[token]:\n",
    "                    scores[doc_id] += self.calculate_bm25_score(query_tokens, doc_id)\n",
    "\n",
    "        top_k = sorted(scores.items(), key=lambda x: x[1], reverse = True)[:k]\n",
    "        return [(doc_id, score, self.documents[doc_id]) for doc_id, score in top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21900/21900 [00:48<00:00, 454.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# add docs\n",
    "from tqdm import tqdm\n",
    "\n",
    "index = InvertedIndex()\n",
    "for idx, data in enumerate(tqdm(dataset)):\n",
    "    question = data['question']\n",
    "    answer = data['response']\n",
    "    index.add_document(idx, question, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비슷한 문제들을 참고해서 만들게 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndataset2 = dataset[5000:10000] # 동재\\ndataset3 = dataset[10000:15000] # 기홍\\ndataset4 = dataset[15000:20000] # 경도\\ndataset5 = dataset[20000:]\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(dataset))\n",
    "dataset = dataset.select(range(625))\n",
    "print(type(dataset))\n",
    "'''\n",
    "dataset2 = dataset[5000:10000] # 동재\n",
    "dataset3 = dataset[10000:15000] # 기홍\n",
    "dataset4 = dataset[15000:20000] # 경도\n",
    "dataset5 = dataset[20000:]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "dotenv_path = os.path.join(os.getcwd(), '.env')\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "openai_key = os.getenv('OPENAI_TEAM_API_KEY')\n",
    "client = openai.OpenAI(api_key=openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are given two pairs of reference questions and reference answers.\n",
    "Your role is a questioner who make a new question.\n",
    "When making your questions, consider the following.\n",
    "1. New Question must require choices such as 'Which is right', 'Which is not right', 'Which is most appropriate', and 'Which is not most appropriate'.\n",
    "2. You have to make 5 choices, 1 answer choice and 4 wrong choices.\n",
    "3. The choices must be generated in association with one of several keywords in the reference question and answer.\n",
    "4. The wrong answer and the right answer are confused, but the wrong answer must be a clear wrong answer.\n",
    "5. The choices does not deviate from the subject of the problem, but it must be different.\n",
    "6. The choices sentence must be similar in length.\n",
    "7. If a person is a financial expert, the person can solve the problem, but if the person is a beginner in financial knowledge, please make the problem with a difficulty that the person cannot solve because it is difficult.\n",
    "8. Please don't create a problem that can be solved by reading other than the problem.\n",
    "please write in Korean and you must write the answer on the last line.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt =\"\"\"\n",
    "### Reference\n",
    "### Question 1: {}\n",
    "### Answer 1: {}\n",
    "\n",
    "### Question 2: {}\n",
    "### Answer 2: {}\n",
    "\n",
    "### New Question : \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/625 [00:26<4:38:28, 26.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI 시스템이 금융 서비스에서 의사결정을 내릴 때, 윤리적 고려사항과 투명성을 아우르기 위해 어떤 조치를 취하는 것이 가장 적절한가요? \n",
      "\n",
      "다음 중 가장 적절한 방안은 무엇인가요?\n",
      "\n",
      "1. **고객 피드백을 반영해 AI의 학습 데이터를 정기적으로 수정하는 것**  \n",
      "2. **AI 시스템의 의사결정에 대한 설명을 제공하지 않는 것**  \n",
      "3. **윤리적 기준 없이 성과 목표만 중시하는 것**  \n",
      "4. **전문가와의 협의 없이 혼자서 데이터 결정을 내리는 것**  \n",
      "5. **데이터 품질 개선을 위한 외부 데이터를 활용하는 것**  \n",
      "\n",
      "정답은 1번입니다.\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 101/625 [30:20<3:19:06, 22.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI 시스템의 공정성, 투명성 및 설명 가능성을 보장하기 위한 금융 서비스 조직의 정책 및 절차 중에서 가장 적절한 것은 무엇인가요?  \n",
      "\n",
      "1. 정책 개발 시 AI 의사결정 모델의 검토 및 평가 절차를 포함해야 한다.  \n",
      "2. 교육 프로그램을 생략하고, 개발자와 사용자들에게 별도로 교육할 필요가 없다.  \n",
      "3. 데이터 관리 체계에서 편향을 최소화하기 위한 기준을 마련해야 한다.  \n",
      "4. 고객 피드백은 반영하지 않고, 내부 평가만 필요하다.  \n",
      "5. AI 시스템은 사용자가 이해할 수 없는 방식으로 작동해야 한다.  \n",
      "\n",
      "정답: 1. 정책 개발 시 AI 의사결정 모델의 검토 및 평가 절차를 포함해야 한다.\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 201/625 [56:25<2:24:57, 20.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기계 학습(ML) 알고리즘을 개발할 때, 과적합(overfitting) 문제를 방지하기 위해 어떤 방법이 가장 적절한가요? 다음 중 가장 적절하지 않은 방법은 무엇인가요?\n",
      "\n",
      "1. **교차 검증**: 데이터를 여러 부분으로 나누어 훈련 및 테스트를 반복하여 모델 성능을 정확하게 평가하는 방법입니다.\n",
      "\n",
      "2. **드롭아웃(Dropout)**: 신경망의 일부 노드를 무작위로 제거하여 과적합을 방지하는 기법입니다.\n",
      "\n",
      "3. **과도한 데이터 축소**: 훈련 데이터의 양을 의도적으로 줄여 모델의 학습을 어렵게 만드는 방법입니다.\n",
      "\n",
      "4. **정규화(Regularization)**: 모델의 복잡도를 줄여 과적합을 방지하는 기술입니다.\n",
      "\n",
      "5. **모델의 복잡성 증가**: 복잡한 모델을 사용하여 더 많은 특징을 학습하게 하는 방법입니다.\n",
      "\n",
      "가장 적절하지 않은 방법은 3번입니다.\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 301/625 [1:26:12<1:15:21, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI 시스템이 금융 서비스에서 발생할 수 있는 편견을 방지하기 위해서는 어떤 조치가 필요한가요? 다음 중 가장 적절한 조치는 무엇인가요?\n",
      "\n",
      "1. 데이터 수집 시 특정 인구 집단을 의도적으로 과대 표현하는 것\n",
      "2. AI 모델의 결정 과정을 불투명하게 유지하는 것\n",
      "3. 다양한 인구 집단을 포괄하는 통계 자료를 포함해 데이터의 균형을 맞추는 것\n",
      "4. 알고리즘의 편향 요소를 정기적으로 평가하지 않는 것\n",
      "5. 금융 서비스 제공 후 고객 피드백을 무시하는 것\n",
      "\n",
      "정답: 3. 다양한 인구 집단을 포괄하는 통계 자료를 포함해 데이터의 균형을 맞추는 것\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 401/625 [1:54:57<51:46, 13.87s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중국과 인도가 금융 포용성을 제고하기 위해 시행한 조치 중 가장 적절하지 않은 것은 무엇인가요?\n",
      "\n",
      "1. 마이크로파이낸스를 통한 저소득층 지원 확대\n",
      "2. 정부 주도의 금융 교육 프로그램 강화\n",
      "3. 금융 서비스 접근성을 증가시키기 위해 디지털 결제 시스템 확산\n",
      "4. 개인 신용 기록의 디지털화 없이 아날로그 방법 고수\n",
      "5. 소규모 기업에 대한 자본 접근성 개선\n",
      "\n",
      "정답: 4. 개인 신용 기록의 디지털화 없이 아날로그 방법 고수\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 501/625 [2:21:51<35:17, 17.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해결 기금의 관리에서 가장 적절한 요소는 무엇이며, 해당 요소가 은행 안정성에 어떻게 영향을 미치는지 설명하세요.\n",
      "\n",
      "1. 자본의 적정성은 은행의 리스크 관리에 핵심적인 역할을 합니다.\n",
      "2. 자본 구조의 다양성은 은행 안정성에 부정적인 영향을 미칩니다.\n",
      "3. 자본의 적정성은 외부의 심리적 안전감을 저해합니다.\n",
      "4. 자본의 과잉 적정성은 금융 취약성을 증가시킵니다.\n",
      "5. 자본의 적정성은 고객의 예금을 보호하는 데 직접적인 기여를 합니다.\n",
      "\n",
      "정답: 1.\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 601/625 [2:46:57<05:24, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "금융 소비자가 기만적인 금융 관행으로부터 보호받기 위해서는 어떤 정책이 가장 적절한가? 다음 중 가장 적절한 정책은 무엇인가?\n",
      "\n",
      "1. 금융 기관의 영업 비밀 보호를 강화하는 정책\n",
      "2. 소비자에게 금융 상품 정보 제공을 의무화하는 정책\n",
      "3. 금융 소비자의 불만을 공개적으로 처리하는 정책\n",
      "4. 금융 교육을 제공하지 않는 정책\n",
      "5. 금융 상품의 가격 인상을 유도하는 정책\n",
      "\n",
      "정답: 2. 소비자에게 금융 상품 정보 제공을 의무화하는 정책\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [2:52:59<00:00, 16.61s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_questions = []\n",
    "for idx, data in enumerate(tqdm(dataset, total=len(dataset))):\n",
    "    question = data['question']\n",
    "    answer = data['response']\n",
    "    system_msg = {'role':'system', 'content': system_prompt}\n",
    "\n",
    "    similar_questions = index.search(question, k=2)\n",
    "\n",
    "    user_msg = {'role':'user', 'content': user_prompt.format(\n",
    "        similar_questions[0][2]['question'],\n",
    "        similar_questions[0][2]['answer'],\n",
    "        similar_questions[1][2]['question'],\n",
    "        similar_questions[1][2]['answer'])}\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages = [system_msg, user_msg],\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "    new_questions.append(result)\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        print(result)\n",
    "        print(\"*\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV 파일로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcqa_data = []\n",
    "\n",
    "for raw_question in new_questions:\n",
    "    lines = [line.strip() for line in raw_question.split('\\n') if line.strip() != '']\n",
    "    question = lines[:-1]\n",
    "    answer = lines[-1]\n",
    "    \n",
    "    for i in range(6):\n",
    "        if str(i) in answer:\n",
    "            answer = i\n",
    "            break\n",
    "\n",
    "    item = {\"question\": question, 'answer': answer}\n",
    "    mcqa_data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result_df = pd.DataFrame(mcqa_data)\n",
    "result_df.to_csv('/root/KRX_LLM/data/mcqa_data1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
